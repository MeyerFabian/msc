\documentclass[m,times]{cgMA}
\usepackage{listings}
\usepackage{xurl}
\urlstyle{sf}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{textcomp}
\usepackage{caption}
\usepackage{color}
\usepackage{subfigure}
\usepackage{wrapfig}
\usepackage[english,ngerman]{babel}
\usepackage[backend=biber,style=alphabetic]{biblatex}
\usepackage{algorithm}% http://ctan.org/pkg/algorithms
\usepackage{algpseudocode}% http://ctan.org/pkg/algorithmicx
\usepackage{mathtools}
\usepackage{subdepth}
\usepackage{enumitem}
\usepackage[toc,page]{appendix}
\usepackage{minted}
\usepackage{verbatim}
\addbibresource{mscthesis.bib}

\DeclareMathOperator*{\argmin}{argmin}
\makeatletter
\def\ext@algorithm{lol}% algorithm captions will be written to the .lol file
% share the list making commands and redefine the heading
\AtBeginDocument{%
  \let\l@algorithm\l@lstlisting
  \let\c@algorithm\c@lstlisting
  \let\thealgorithm\thelstlisting
  \renewcommand{\lstlistlistingname}{Algorithms and source code}%
}
\makeatother
\lstdefinelanguage{GLSL}
{
  sensitive=true,
  morekeywords=[1]{
    attribute, const, uniform, varying,
    layout, centroid, flat, smooth,
    noperspective, break, continue, do,
    for, while, switch, case, default, if,
    else, in, out, inout, float, int, void,
    bool, true, false, invariant, discard,
    return, mat2, mat3, mat4, mat2x2, mat2x3,
    mat2x4, mat3x2, mat3x3, mat3x4, mat4x2,
    mat4x3, mat4x4, vec2, vec3, vec4, ivec2,
    ivec3, ivec4, bvec2, bvec3, bvec4, uint,
    uvec2, uvec3, uvec4, lowp, mediump, highp,
    precision, sampler1D, sampler2D, sampler3D,
    samplerCube, sampler1DShadow,
    sampler2DShadow, samplerCubeShadow,
    sampler1DArray, sampler2DArray,
    sampler1DArrayShadow, sampler2DArrayShadow,
    isampler1D, isampler2D, isampler3D,
    isamplerCube, isampler1DArray,
    isampler2DArray, usampler1D, usampler2D,
    usampler3D, usamplerCube, usampler1DArray,
    usampler2DArray, sampler2DRect,
    sampler2DRectShadow, isampler2DRect,
    usampler2DRect, samplerBuffer,
    isamplerBuffer, usamplerBuffer, sampler2DMS,
    isampler2DMS, usampler2DMS,
    sampler2DMSArray, isampler2DMSArray,
  usampler2DMSArray, struct},
  morekeywords=[2]{
    radians,degrees,sin,cos,tan,asin,acos,atan,
    atan,sinh,cosh,tanh,asinh,acosh,atanh,pow,
    exp,log,exp2,log2,sqrt,inversesqrt,abs,sign,
    floor,trunc,round,roundEven,ceil,fract,mod,modf,
    min,max,clamp,mix,step,smoothstep,isnan,isinf,
    floatBitsToInt,floatBitsToUint,intBitsToFloat,
    uintBitsToFloat,length,distance,dot,cross,
    normalize,faceforward,reflect,refract,
    matrixCompMult,outerProduct,transpose,
    determinant,inverse,lessThan,lessThanEqual,
    greaterThan,greaterThanEqual,equal,notEqual,
    any,all,not,textureSize,texture,textureProj,
    textureLod,textureOffset,texelFetch,
    texelFetchOffset,textureProjOffset,
    textureLodOffset,textureProjLod,
    textureProjLodOffset,textureGrad,
    textureGradOffset,textureProjGrad,
    textureProjGradOffset,texture1D,texture1DProj,
    texture1DProjLod,texture2D,texture2DProj,
    texture2DLod,texture2DProjLod,texture3D,
    texture3DProj,texture3DLod,texture3DProjLod,
    textureCube,textureCubeLod,shadow1D,shadow2D,
    shadow1DProj,shadow2DProj,shadow1DLod,
    shadow2DLod,shadow1DProjLod,shadow2DProjLod,
    dFdx,dFdy,fwidth,noise1,noise2,noise3,noise4,
  EmitVertex,EndPrimitive},
  morekeywords=[3]{
    gl_VertexID,gl_InstanceID,gl_Position,
    gl_PointSize,gl_ClipDistance,gl_PerVertex,
    gl_Layer,gl_ClipVertex,gl_FragCoord,
    gl_FrontFacing,gl_ClipDistance,gl_FragColor,
    gl_FragData,gl_MaxDrawBuffers,gl_FragDepth,
    gl_PointCoord,gl_PrimitiveID,
    gl_MaxVertexAttribs,gl_MaxVertexUniformComponents,
    gl_MaxVaryingFloats,gl_MaxVaryingComponents,
    gl_MaxVertexOutputComponents,
    gl_MaxGeometryInputComponents,
    gl_MaxGeometryOutputComponents,
    gl_MaxFragmentInputComponents,
    gl_MaxVertexTextureImageUnits,
    gl_MaxCombinedTextureImageUnits,
    gl_MaxTextureImageUnits,
    gl_MaxFragmentUniformComponents,
    gl_MaxDrawBuffers,gl_MaxClipDistances,
    gl_MaxGeometryTextureImageUnits,
    gl_MaxGeometryOutputVertices,
    gl_MaxGeometryOutputVertices,
    gl_MaxGeometryTotalOutputComponents,
    gl_MaxGeometryUniformComponents,
  gl_MaxGeometryVaryingComponents,gl_DepthRange},
  morecomment=[l]{//},
  morecomment=[s]{/*}{*/},
  morecomment=[l][keywordstyle4]{\#},
}
\lstdefinestyle{GL}{
  tabsize=2,
  rulecolor=,
  basicstyle=\scriptsize,
  upquote=true,
  aboveskip={0.5\baselineskip},
  belowskip={1.5\baselineskip},
  columns=fixed,
  showstringspaces=false,
  extendedchars=true,
  breaklines=true,
  prebreak = \raisebox{0ex}[0ex][0ex]{\ensuremath{\hookleftarrow}},
  frame=single,
  showtabs=false,
  showspaces=false,
  showstringspaces=false,
  identifierstyle=\ttfamily,
  keywordstyle=\color[rgb]{1.0,0,0},
  keywordstyle=[1]\color[rgb]{0,0,0.75},
  keywordstyle=[2]\color[rgb]{0.5,0.0,0.0},
  keywordstyle=[3]\color[rgb]{0.127,0.427,0.514},
  keywordstyle=[4]\color[rgb]{0.4,0.4,0.4},
  commentstyle=\color[rgb]{0.133,0.545,0.133},
  stringstyle=\color[rgb]{0.639,0.082,0.082},
  numbers=left,
}

\newenvironment{code}{\captionsetup{type=algorithm}}{}
\begin{document}
\author{Fabian Meyer}
\title{GPU-Beschleunigung der Material Point Method}
\zweitgutachter{Bastian Krayer, M.Sc.}
\zweitgutachterInfo{(Institut f{\"u}r Computervisualistik, AG Computergraphik)}
% Umschalten der Sprache (fuer englische Rubrikbezeichnungen etc.)

\pagenumbering{roman}
\maketitle

\clearpage
\selectlanguage{english}
\subsubsection*{Abstract}

\noindent Physic

%\vfill~
%ggf. noch'n \vfill~

\clearpage
\tableofcontents

%\setcounter{page}{3}
\clearpage         % oder \cleardoublepage bei zweiseitigem Druck
% \listoffigures   % fuer ein eventuelles Abbildungsverzeichnis
% \clearpage
\pagenumbering{arabic}


\section{Introduction} \label{intro}
bib-test \cite{MPM:SNOW}
$$ -  \int_{\pi/2}^{\pi} \frac{1}{\sqrt{u}} \frac{\lvert \cos{x} \rvert}{\cos{x}} du $$
\section{Related Work}
\cite{PIC:GPU} -> \cite{NVIDIA:NNSEARCH}\\
\cite{stantchev2008fast}\\
benefits over radix sort /thrust sort-by-key -> counting sort
\cite{NVIDIA:SHUFFLE}\\
\cite{MPM:POLYPIC}\\
\cite{MPM:GPU}\\
%look again for MPM/PIC gpu impl
%SPH, FEM methods
\section{Notation}\label{sec:notation}
Multi-component types are generally printed in bold letters $\boldsymbol{A}$, $\boldsymbol{a}$. Vectors furthermore use lower-case letters $\boldsymbol{v}$, while Matrices use upper-case letters $\boldsymbol{M}$. A variable in the Lagrangian form has a subscript 0 $ _0{\boldsymbol{x}}$, the Eulerian description will be written with an 'overline' $_t\boldsymbol{x}$ if distinction is needed. Occasionally notation may be omitted where it is apparent from context. Beginning from chapter \ref{sec:mat_point} variables defined on a particle will have subscript $p$ (e.g. $\boldsymbol{x}_p$). Grid cells will be assigned a subscript $i$ denoting the grid index (e.g. $\boldsymbol{x}_i$). This is not to be confused with the following Einstein-Notation. Therefore beginning with chapter \ref{sec:mat_point} Einstein-Notation for components will use greek letters ($\alpha,\beta$). Occasionally summation over grid index $i$ and particles $p$ may be implied. A variable of the $n$-th time step with associated time $t^n = \sum_{i=1}^{n} t^i$ will have a right superscript: $\boldsymbol{x}^n$.
\subsection{Einstein-Notation}
Used throughout this thesis is at instances the Einstein-Notation when using tensors and vectors. Let $\boldsymbol{a}$ and $\boldsymbol{b}$ be vectors of dimension $n$ and  $\boldsymbol{A,B,D}$ $ { m \times n }$ tensors. Repeated indices that are also defined on the variable imply component-wise operations.
$a _ { i } b _ { j }$ is multiplying component $i$ with component $j$ of vectors $\boldsymbol{a}$ and $\boldsymbol{b}$. Vector and tensor/matrix addition thus become:
\begin{equation} \label{EINSTEIN:ADD}
  c _ { i } = a _ { i } + b _ { i } \quad \text { and } \quad D _ { i j } = A _ { i j } + B _ { i j }
\end{equation}
A transpose operator swaps the indices:
\begin{equation}
  D^T _ { i j }  =D_{ji}
\end{equation}
Repeated indices that are not otherwise defined however imply summation on that index. The vector dot product becomes:
\begin{equation}
  a _ { i } b _ { i } \equiv \sum _ { i = 1 } ^ { n } a _ { i } b _ { i }
\end{equation}
Following this notation the Frobenius inner product between two second-order tensors is (also called Frobenius scalar product):
\begin{equation} \label{EINSTEIN:FROBENIUS1}
  \boldsymbol { A } : \boldsymbol { B } \equiv A _ { i j } B _ { i j } \equiv \sum _ { i = 1 } ^ { n } \sum _ { j = 1 } ^ { m } A _ { ij } B _ { ij }
\end{equation}
The Frobenius inner product between a ${r \times s \times m \times n }$ fourth-order tensor $\boldsymbol{C}$  and second-order tensor creates a second order tensor combining the ideas of \ref{EINSTEIN:ADD} and \ref{EINSTEIN:FROBENIUS1}:
\begin{equation}
  \boldsymbol { A } = A_ {ij} =  \boldsymbol {C} : \boldsymbol { B } = C _ {i j k l} B _ { k l  } = \sum _ { k = 1 } ^ { m } \sum _ { l = 1 } ^ { n } C _ { ijkl } B _ { kl }
\end{equation}
Matrix-Vector and Matrix-Matrix multiplication can be expressed this way as:
\begin{equation}
  b_i = A_{i j} a_j \quad D _ { i j } = A _ { i k } B _ { k j }
\end{equation}
The definition of the Kronecker Delta is as follows:
\begin{equation}
  \delta _ { i j } = \left\{
    \begin{array} { l l l }
      { 1 } & {\text{if}} &  {i = j}  \\
      { 0 } & {\text{if}} &  { i \neq j }
  \end{array} \right.
\end{equation}
The Kronecker Delta as an operator is most efficiently described as a substitution:
\begin{equation}
  a _ { i } \delta _ { i j } = a _ { j }
\end{equation}
I.e. this component is only evaluated if $i = j$. In this case it becomes equivalent to the identity matrix $\boldsymbol{I}$. The Kronecker Delta comes up in differentiating a variable by itself with different indexing:
\begin{equation}
  \frac{\partial{x_0}}{\partial{x_1}}=0, \frac{\partial{x_0}}{\partial{x_0}}=1  \Rightarrow \frac{\partial{x_i}}{\partial{x_j}} = \delta_{ij}
\end{equation}
The alternating tensor or Levi-Civita symbol
\begin{equation}
  \varepsilon _ { i j k } = \left\{ \begin{array} { r l } { + 1 } & { \text { if } ( i , j , k ) \text { is } ( 1,2,3 ) , ( 2,3,1 ) , \text { or } ( 3,1,2 ) } \\ { - 1 } & { \text { if } ( i , j , k ) \text { is } ( 3,2,1 ) , ( 1,3,2 ) , \text { or } ( 2,1,3 ) } \\ { 0 } & { \text { if } i = j , \text { or } j = k , \text { or } k = i } \end{array} \right.
\end{equation}
is used to express cross-products $\boldsymbol{c}=\boldsymbol{a} \times \boldsymbol{b}$:
\begin{equation}
  c_i = \varepsilon_{ijk} a_j b_k \left(= \sum _ { j = 1 } ^ { n } \sum _ { k = 1 } ^ { n } \varepsilon_{ijk} a_j b_k\right).
\end{equation}
A useful relation to the Kronecker-Delta is:
\begin{equation} \label{eq:compact_levi}
  \varepsilon _ { i j k } \varepsilon _ { i m n } = \delta _ { j m } \delta _ { k n } - \delta _ { j n } \delta _ { k m }.
\end{equation}
\cite{MCGINTY:CONTINUUM}
\section{Basics}
\subsection{Reference and current configuration}
Particles (or material points) in continuum mechanics are not what classically might be thought of as a particle. Rather the continuum assumption holds: each particle represents a continuous piece of material, s.t. a microscopic view does not need to be adopted. A particular body is composed of a set of particles and can adapt different configurations due to changes in shape. These changes are cause by external or internal effects (forces etc.) on it and deform the body over time. \cite{MIT:CONTINUUM_MECHANICS} \cite{MPM:COURSE}


When modelling solids changes of quantities from a initial reference configuration $_0\boldsymbol{x}$ to another current configuration $_t\boldsymbol{x}$ need to be measured. In the material point method the reference configuration $^0\boldsymbol{x}$ is just the initial configuration of the body (at time $t=0$). This is similar to the total Lagrangian formulation in finite element methods \cite{bathe2006finite}.
Let $\Omega ^ { 0 } , \Omega ^ { t } \subset \mathbb { R } ^ {  { 3 } }$ be the set of (material) points in the reference and current configuration respectively.  Then one may define a function or mapping ${^t_0}\phi ( \cdot , t ) : \Omega ^ { 0 } \rightarrow \Omega ^ { t }$, which relates the reference configuration to the current configuration. If we assume for simplicity that $_0\boldsymbol{x}$ and $_t\boldsymbol{{x}}$ describe the position of the particle in their respective configurations, this mapping becomes the deformation of the body from the reference configuration $_0\boldsymbol{x}$:
\begin{equation}
  _t\boldsymbol{x} =  {^t_0}\phi ( _0\boldsymbol{x} , \boldsymbol { t } )
\end{equation}
If for instance the body consisting of each material point $_t\boldsymbol{x}$ moves with velocity $\boldsymbol{v}$ and rotation $\boldsymbol{R}(t)$ , we can defines this mapping to be:
\begin{equation}\label{eq:rigid}
  _t\boldsymbol{{x}} = {^t_0}\phi ( _0\boldsymbol{x} , \boldsymbol { t } ) = \boldsymbol{R}(t)_0\boldsymbol{x}+\boldsymbol{v}t
\end{equation}
The velocity of a material point in $_0\boldsymbol{x}$ can be defined using this mapping
\begin{equation}\label{eq:velocity}
  _0\boldsymbol{v}(_0\boldsymbol{x},t) = \frac{\partial {^t_0}\phi}{\partial t}(_0\boldsymbol{x},t)
\end{equation}
and similarly the acceleration is defined
\begin{equation}
  _0\boldsymbol{a}(_0\boldsymbol{x},t) = \frac{\partial^2 {^t_0}\phi}{\partial t^2}(_0\boldsymbol{x},t) = \frac{\partial _0\boldsymbol{v}}{\partial t}(_0\boldsymbol{x},t).
\end{equation}
It is helpful to abstract away from the reference configuration and think of it as being defined in a different fixed material space. Physically this has the impact of moving with the particle in world space. Commonly known as the Lagrangian form. It is often easier in continuum mechanics to start with a Lagrangian description and switch to a Eulerian one if needed. The Eulerian description is static: Variables of particles that are moving by are measured while staying in a fixed position.
These descriptions are different but they will yield the same measurements when related correctly. I.e. both configuration refer variables defined on them do the deformed state, but the position where we 'look up' that value is different. In the reference configuration we look up at the initial position of the particle. In the current configuration we look up at the particle's 'world position'. These relations for some particle quantity $f$ are called the (Lagrangian) pull back
\begin{equation}
  _0f(_0\boldsymbol{x},t)= {_tf}({^t_0}\phi(_0\boldsymbol{x},t),t)
\end{equation}
and the (Eulerian) push forward
\begin{equation}\label{eq:push_forward}
  _tf(_t\boldsymbol{x},t) =  {_0f}({^t_0}\phi^{-1}(_t\boldsymbol{x},t),t) = {_0f}({_t^0}\phi(_t\boldsymbol{x},t),t)
\end{equation}
with definitions over their respective spaces $_tf ( \cdot , t ) : \Omega ^ {  { t } } \rightarrow \mathbb { R }$, $_0f ( \cdot , t ) : \Omega ^ {   { 0 } } \rightarrow \mathbb { R }$.  To enable the operator ${^t_0}\phi$ to be homeomorphic, s.t. an inverse ${^t_0}\phi^{-1} = {_t^0}\phi$ is defined, it is assumed that no two particles will ever occupy the same space at the same time.

The difficulty in the eulerian formulation becomes apparent when differentiating (due to the chain rule):
\begin{equation} \label{eq:eulerian_general}
  \frac {\partial}{\partial t} {_0f_i } ( {_0\boldsymbol { x }} ,  t  ) =
  \frac { \partial  {_tf_i} } { \partial t } ( {^t_0}\phi ( {_0\boldsymbol {x }} , t ) , t ) + \frac { \partial  {_tf_i }} { \partial {_tx_j} } ( {^t_0}\phi ( {_0\boldsymbol { x }} , t ) , t ) \frac { \partial {^t_0}\phi_j } { \partial t } ( {_0\boldsymbol { x }} , t )
\end{equation}
Combining this with equation \ref{eq:velocity} and applying the push forward \ref{eq:push_forward} to cancel out mappings leads to the definition referred to as the material derivative:
\begin{equation} \label{eq:material_derivative}
  \frac {  { D } } {   { D }   { t } }   {  {f} } ( _t\boldsymbol { x } ,   { t } ) = \frac { \partial   {  {f} } } { \partial   { t } } ( _t\boldsymbol {x } ,   { t } ) + \frac { \partial   {  {f} } } { \partial x _ {   { j } } } ( _t{\boldsymbol { x }} ,   { t } )  {v} _ {   { j } } ( _t\boldsymbol { x } ,   { t } )
\end{equation}
The Jacobian of the deformation map $\phi$ is the deformation gradient $\boldsymbol{F}$ and is one of the key components to measure strain:
\begin{equation}
  {^t_0 F_{ij}} ( _0\boldsymbol {x} ,  t  ) = \frac { \partial {^t_0\phi_i} } { \partial _0 x _j } ( _0\boldsymbol { x } , t ) = \frac { \partial _t x _i } { \partial _0 x_j } ( _0\boldsymbol { x } , t )
\end{equation}
Intuitively it measures the local deformation of all particles in a small neighborhood of $_0B_\epsilon$ to $_tB_\epsilon$. Topology specifies the neighborhood using the open ball concept $_{0,t}B_\epsilon(\boldsymbol{x}) = \{\boldsymbol{y} \in {\Omega^{0,t} | d(\boldsymbol{x},\boldsymbol{y}) < \epsilon}\}$ given a distance measure $d$. $_0B_\epsilon$ becomes the pre-image of $_tB_\epsilon$ under $_0^t\phi$. This allows to describe infinitesimal changes in position from the reference to the current configuration
\begin{equation}\label{eq:def_grad_pos}
  d {_tx_i} = {^t_0}F{_{ij}} d{_0x_j}.
\end{equation}
With this quantity in place volume and area changes are calculable. In a typical analytical fashion a coordinate system change $_0x \rightarrow {_tx}$ is done using the Jacobian (determinant) matrix. The determinant is given a separate name $^t_0J =\text{det}(^t_0\boldsymbol{F})$. The push forward of $_0g:\Omega^0\rightarrow \mathbb{R}^d$ is $_tg:\Omega^t\rightarrow \mathbb{R}^d$:
\begin{equation} \label{eq:volume_integral}
  \int _ { {_t\boldsymbol { B } }}  {_tg} ( {_t\boldsymbol { x }} ,t)  d {_t\boldsymbol { x }} = \int _ { { _0\boldsymbol { B }}} {_0 g } ( {_0\boldsymbol{x}},t) {^t_0 J}d {_0\boldsymbol{x}}.
\end{equation}
This can also be achieved by the cross product. A cube spanned by vectors $_0\boldsymbol{x}_i$ ($i=1,2,3$) becomes a parallelepiped in the deformed configuration $d_tV =|{^t_0\boldsymbol{F}}d_0\boldsymbol{x}_0 \cdot({^t_0\boldsymbol{F}}d_0\boldsymbol{x}_1 \times {^t_0\boldsymbol{F}}d_0\boldsymbol{x}_2)| {d_0V}$:
\begin{equation}\label{eq:j}
  d_tV = {^t_0J} d_0V.
\end{equation}
The area change is given by Nanson's Formula. Where $d\boldsymbol{A}$ is a vector pointing in the direction of the normal of the area:
$$ d{_tV} = d{_t\boldsymbol{A}} \cdot d{_t\boldsymbol{l}}, \quad d{_0V} = d{_0\boldsymbol{A}}\cdot d{_0\boldsymbol{l}} $$
$$ \xRightarrow{\ref{eq:def_grad_pos},\ref{eq:j}} {^t_0J} d_0\boldsymbol{A} \cdot d_0\boldsymbol{l} = d{_t\boldsymbol{A}} \cdot ({^t_0\boldsymbol{F}}d{_0\boldsymbol{l}})$$
\begin{equation}
  \Rightarrow d_t\boldsymbol{A} = {^t_0\boldsymbol{F}}^{-T} {^t_0}J d_0\boldsymbol{A} = {^0_t\boldsymbol{F}}^{T} {^t_0}J d_0\boldsymbol{A}.
\end{equation}
A surface integral may then be transformed to reference configuration by
\begin{equation}\label{eq:surface_integral}
  \int _ { \partial {_0B}  } \boldsymbol{h} ( {_t\boldsymbol{x}} , t ) \cdot d \boldsymbol{A} ( {_t\boldsymbol{x}} ) =  \int _ { \partial {_tB} } \boldsymbol{h} ( {_0\boldsymbol{x}} , t ) \cdot \boldsymbol{F}^{-T}J d \boldsymbol{A} ( {_0\boldsymbol{x}} )
\end{equation}
where $_0\boldsymbol{h} = \boldsymbol{h}(_0\boldsymbol{x},\cdot)$ is the pull back of $_t\boldsymbol{h} = \boldsymbol{h}(_t\boldsymbol{x},\cdot)$. $d_0\boldsymbol{A}$,$d_t\boldsymbol{A}$ point in the direction of the surface normal of $\partial {_0B}(_0\boldsymbol{x})$, $\partial {_tB}(_t\boldsymbol{x})$, respectively.
\cite{MIT:CONTINUUM_MECHANICS}
\cite{MPM:COURSE}
\subsection{Polar- and Singular Value Decomposition}
The target is to define strain measures in terms of the deformation gradient: $\boldsymbol{\epsilon}(\boldsymbol{F})$. In equation \ref{eq:rigid} a rigid body movement was introduced. A problem arises when calculating the deformation gradient of this equation.
Let $b_i(t) = v_it$ be more generally a translation:
\begin{equation}
  ^t_0F_{ij} = \frac{\partial{_tx_i}}{\partial_0x_j} = \frac{\partial (R_{ik}(t)_0x_k+b_i(t))}{\partial _0x_j} = R_{ik}(t) \delta_{kj} = R_{ij}(t)
\end{equation}
As can be seen the deformation gradient contains a rigid rotation. For strain measures this is not beneficial as an assumption of the stiffness tensor requires no net-rotation. I.e. the deformation gradient has two components a constant rotation and the actual distortion or strain. There is two ways to deal with this:
\begin{enumerate}
  \item  Use a strain measure that cancels out the rotation. An example for this would be the Green-strain with quadratic components:
    \begin{equation}\label{eq:green}
      E _ { i j } = \frac { 1 } { 2 } \left( F _ { k i } F _ { k j } - \delta _ { i j } \right).
    \end{equation}
  \item \label{it:polar} Polar decompose the deformation gradient in its rotational $\boldsymbol{R}$ and (symmetric positive definite) distortion $\boldsymbol{S}$ part $\boldsymbol{F}=\boldsymbol{R}\boldsymbol{S}$.
\end{enumerate}
That equation \ref{eq:green} cancels out the rotational part can be shown by item \ref{it:polar}:
$$ \frac { 1 } { 2 } \left( F _ { k i } F _ { k j } - \delta _ { i j } \right) = \frac { 1 } { 2 } \left( S _ {m i}R_{k m} R _ { k n} S_{n j} - \delta _ { i j } \right)$$
$$= \frac { 1 } { 2 } \left( S _ {m i} \delta_{mn} S_{n j} - \delta _ { i j } \right) = \frac { 1 } { 2 } \left( S _ {i m} S_{m j} - \delta _ { i j } \right)$$
$$= \frac{1}{2} \left(\boldsymbol{S}^2 - I \right).$$
Regarding item \ref{it:polar}: Assuming a singular value decomposition of
\begin{equation}\label{eq:svd}
  \boldsymbol{F} = \boldsymbol{U\Sigma V}^T
\end{equation}
is already computed, where $\boldsymbol{U}$,$\boldsymbol{V}$ are orthogonal matrices and $\boldsymbol{\Sigma}$ is a diagonal matrix containing the singular values $\sigma_1 \geq \sigma_2 \geq ... \geq \sigma_r$ of $\boldsymbol{F}$. $(r-n)$ forms the dimension of the null space. The polar decomposition is computable as:
\begin{equation}
  \boldsymbol{R} = \boldsymbol{V} \boldsymbol{W} ^ { T }, \quad \boldsymbol{S} = \boldsymbol{W} \boldsymbol{\Sigma} \boldsymbol{W} ^ { T }.
\end{equation}
Since singular values are positive, it is straightforward to see that the properties for $\boldsymbol{R}$ and $\boldsymbol{S}$ hold.
The components of the singular value decomposition are important to gain an intuition: The columns of $\boldsymbol{U}$ and $\boldsymbol{V}$ span bases for the row and column spaces of $\boldsymbol{F}$ using the left and right singular vectors $\boldsymbol{u}_i,\boldsymbol{v}_i$, respectively \cite{MIT:SVD}. For illustrating purposes imagine the manipulation of $\boldsymbol{v}_1$ due to $\boldsymbol{U\Sigma V}^T$:
\begin{enumerate}
  \item Transform from the right singular vector space to standard basis space: $\boldsymbol{V}^T\boldsymbol{v}_1 = \boldsymbol{e}_1$
  \item Scale by singular values to transform to principal stretch space: $\boldsymbol{\Sigma} \boldsymbol{e}_1 = \sigma_1 \boldsymbol{e}_1$
  \item \label{it:tr_sing_vect} Transform to left singular vector space: $\boldsymbol{U}\sigma_1\boldsymbol{e}_1 = \sigma_1 \boldsymbol{u}_{1}$
\end{enumerate}
For a positive definite matrix the singular value decomposition becomes even easier as $\boldsymbol{U}=\boldsymbol{V}$. Item \ref{it:tr_sing_vect} then effectively just becomes a transform 'back'.
Following is a summary of the $3 \times 3$ singular value decomposition as in \cite{SVD:3x3}. The proposed singular value decomposition is also called 'Polar SVD' and follows a specific convention.
\begin{itemize}\label{ref:itemize_conv}
  \item $\boldsymbol{U}$,$\boldsymbol{V}$ are reflection-free corresponding to true rotation matrices, i.e. both $\text{det}(U), \text{det}(V) = 1$.
  \item As a result if $\text{det}(\boldsymbol{F}) = -1$ the negative sign needs to move on to $\boldsymbol{\Sigma}$: The lowest singular value in magnitude will get a negative sign attached.
\end{itemize}
This convention does not change the existence or uniqueness of the singular value or polar decomposition, although strictly speaking $\boldsymbol{S}$ in the Polar decomposition is not positive definite anymore.
\begin{enumerate}
  \item \label{it:eig} \textbf{Symmetric eigenanalysis:} A Jacobi eigenvalue algorithm begins with the symmetric positive definite matrix $\boldsymbol { S } ^{(0)}= \boldsymbol { A } ^ { T } \boldsymbol { A } = \boldsymbol { V } \boldsymbol { \Sigma } ^ { 2 } \boldsymbol { V } ^ { T }$.
    \begin{enumerate}[label*=\arabic*.]
      \item \label{item:sk} Iteratively compute (an also symmetric, positive definite) $\boldsymbol { S } ^ { ( k + 1 ) } = [ \boldsymbol { Q } ^ { ( k )}] ^ { T } \boldsymbol { S } ^ { ( k ) } \boldsymbol { Q } ^ { ( k ) }$, where $\boldsymbol{Q}$ is a Givens rotation aiming to eliminate off $S_{12}$. Store $\boldsymbol{V}^{(k+1)} = \boldsymbol{V}^{(k)}  \boldsymbol{Q}^{(k)}$.
      \item \label{item:sii} Do \ref{item:sk} again for the other off-diagonal entries $S_{13},S_{23}$.
      \item \label{item:redo_sii} Redo \ref{item:sk} - \ref{item:sii} a fixed amount of steps $m$.
    \end{enumerate}
  \item \textbf{Sorting singular values:} Compute $\boldsymbol{B} := \boldsymbol{AV}$, where $\boldsymbol{V} = \boldsymbol{V}^{(3m)}$. Acquire $\boldsymbol{\Sigma}$ by $\|\boldsymbol{b}_i \|_2 = \|\boldsymbol{u}_i\sigma_i\|_2 = |\sigma_i|$, where also $\boldsymbol{B=U\Sigma}$ holds. Permute the singular values by sorting them in decreasing order. Apply the same permutation to the columns of $\boldsymbol{B}$ and $\boldsymbol{V}$, where switches in $\boldsymbol{V}$ also cause a sign change. Enforce the convention mentioned above.
  \item \label{item:qr} \textbf{QR-Factorization:} Compute $\boldsymbol{U}$ using a $\boldsymbol{QR}$-Factorization with Givens Rotations, where $\boldsymbol{B}=\boldsymbol{QR}=\boldsymbol{U\Sigma}$. The $\boldsymbol{QR}$-Factorization is done once in the same fashion as in item \ref{item:sk} - \ref{item:sii}.
\end{enumerate}
Due to inherent normalization, fast multiplication and storage efficiency quaternions are preferred over actual rotation matrices. In item \ref{item:qr} a $\boldsymbol{QR}$-Factorization is preferred over a column normalization of $\boldsymbol{\Sigma U}$ due to its inaccuracy at near-zero singular values.
\cite{MPM:COURSE}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                         Constitutive Models                         %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Constitutive Models}\label{seq:constitutive_models}
\cite{MPM:DRUCKER} %Sand Plasticity
\cite{MPM:MULTI} %Sand+Water
\cite{MPM:INVERT} %Neo-Hookean
\cite{MPM:OLROYDB} %Viscoelastic Foam,Sponge
\cite{MPM:SHELLS} %Thin Shells
\cite{MPM:PHASE_CHANGE} %Heat-Model
\cite{MPM:OPTIMI_INTEGR} %Opimization Methods, BDF-Semi-Impl-Midpoint rule
$$\boldsymbol{F}_E \boldsymbol{F}_P$$ \cite{ochsner2014elasto}
\subsubsection{Linear Elasticity}\label{sec:linear_elasticty}
The first aim will be to find the strain energy density $\Psi(\boldsymbol{\epsilon})$ of the strain $\bm{\epsilon}$.
For an (hyper-)elastic material the Cauchy stress may be defined in terms of $\Psi$ as:
The most general linear stress-strain relationship is given by Hooke's Law in three dimensions
\begin{equation}\label{eq:hook}
  \sigma_{ij} = C_{ijkl} \epsilon_{kl},
\end{equation}
where $\boldsymbol{\sigma}$ and $\bm{\epsilon}$ are second-order tensors with (3x3) = 9 elements. $C_{ijkl}$ is a fourth-order tensor with (3x3)x(3x3) = 81 elements.
Assuming following symmetries reduces the tensors to 6 and 21 unique elements respectively:
\begin{enumerate}
  \item Conservation of angular momentum: $\sigma_{ij} = \sigma_{ji} \Rightarrow C_{ijkl} = C_{jikl} $
  \item No-net-rotation: $\epsilon_{kl} = \epsilon_{lk} \Rightarrow C_{ijkl} = C_{ijlk}$
  \item \label{it:mixed_partials}Equivalence of second-order mixed partials of $\Psi$:
    \begin{equation}
      C _ { i j k l } = \frac { \partial ^ { 2 } { \Psi } } { \partial \epsilon _ { k l } \partial \epsilon _ { i j } } = \frac { \partial ^ { 2 } { \Psi } } { \partial \epsilon _ { i j } \partial \epsilon _ { k l } } = C _ { k l i j },
    \end{equation}
\end{enumerate}
where item \ref{it:mixed_partials} holds for the strain energy density functional of an (hyper-)elastic material. The stress may then also be calculated by
\begin{equation}\label{eq:partial_energy}
  \sigma _ { i j } = \sigma _ { i j } ( \boldsymbol{\epsilon} ) = \frac { \partial { \Psi } } { \partial \epsilon _ { i j } },
\end{equation}
if such a $\Psi$ is given. An isotropic (direction-independent) linear elastic material further only has three unique elements $C _ {i j k l}$. Using Voigt-Notation, which collapses indices $i=j$ and $k=l$, equation \ref{eq:hook} can be rewritten as:
\begin{equation} \label{eq:voigt}
  \left[ \begin{array} {c}
      {\sigma_{11}}\\
      {\sigma_{22}}\\
      {\sigma_{33}}\\
      {\sigma_{23}}\\
      {\sigma_{13}}\\
      {\sigma_{12}}\\
  \end{array} \right]
  = \left[ \begin{array} { c c c c c c }
      { C _ { 11 }   } & { C _ { 12 } } & { C _ { 12 } } & 0                & 0                & 0 \\
      {}               & { C _ { 11 } } & { C _ { 12 } } & 0                & 0                & 0 \\
      {}               & {}             & { C _ { 11 } } & 0                & 0                & 0 \\
      {}               & {}             & {}             & { C _ { 22 } }   & 0                & 0 \\
      {}               & {}             & {}             & {}               & { C _ { 22 } }   & 0 \\
      {sym}            & {}             & {}             & {}               & {}               & { C _ { 22 } } \\
  \end{array} \right]
  \left[ \begin{array} {c}
      {\epsilon_{11}}\\
      {\epsilon_{22}}\\
      {\epsilon_{33}}\\
      {\gamma_{23}}\\
      {\gamma_{13}}\\
      {\gamma_{12}}\\
  \end{array} \right]
\end{equation}
Experimental results of Hooke's law commonly give
\begin{equation}
  \boldsymbol{\epsilon} =
  \epsilon _ { i j } = \frac { 1 } { E } \left[ ( 1 + \nu ) \sigma _ { i j } - \nu \sigma _ { k k } \delta _ { i j } \right]
  = \boldsymbol{C}^{-1} \bm{\sigma}
\end{equation}
using engineering constants Young's modulus $E$ and Poisson ratio $\nu$. Inverting $\boldsymbol{C}^{-1}$ and switching to Lamé parameters $\lambda$ and $\mu$ results in the equation:
\begin{equation} \label{eq:stress_strain}
  \sigma_{ij} = 2\mu \epsilon_{ij} + \lambda \text{tr}(\boldsymbol{\epsilon}) \delta_{ij}.
\end{equation}
Comparing with equation \ref{eq:voigt} leads to coefficients $\gamma_{ij} = 2\epsilon_{ij} \text{ for } (i \neq j)$, $C_{11} = \lambda +2 \mu$, $C_{12} = \lambda$ and $C_{22} = \mu$. $\gamma$ is also referred to as the engineering strain. Due to the relationship in \ref{eq:partial_energy} the model for linear elasticity in terms of the strain energy density function $\Psi_{LE}$ after integration of \ref{eq:stress_strain} concludes to:
\begin{equation}\label{eq:linear_elas}
  \Psi_{LE} = \mu \Vert \boldsymbol{\epsilon} \Vert^2_F + \frac{\lambda}{2} \text{tr}^2(\boldsymbol{\epsilon}).
\end{equation}
\cite{MIT:LINEAR_ELASTICITY}
\subsubsection{Corotated Hyperelasticity}\label{sec:cor_hyper}
The simplest tensor assumed by infinitesimal strain theory is the small strain tensor: \begin{equation}
  \boldsymbol{\epsilon} = \frac { 1 } { 2 } \left( \boldsymbol { F }_E + \boldsymbol { F }_E ^ { T } \right) - \boldsymbol { I }
\end{equation}
The energy produced by equation \ref{eq:linear_elas} using the small strain tensor is not rotationally invariant, w.r.t. to $\boldsymbol{F}_E$: $\Psi_{LE}(\boldsymbol{\epsilon}(\boldsymbol{R}_{0} \boldsymbol{F}_E)) \neq \Psi_{LE}(\boldsymbol{\epsilon}(\boldsymbol{F}_E))$. Rigid body motions however don't result in strain and consequently don't need to be recovered from. So energy should not change. Given the polar decomposition $\boldsymbol{F}_E = \boldsymbol{R}_E\boldsymbol{S}_E$, an alternate strain measure may be defined as:
\begin{equation}
  { \boldsymbol { \epsilon } } ( \boldsymbol { F }_E ) = \boldsymbol { \epsilon } \left( \boldsymbol { R }_E ^ { T } \boldsymbol { F }_E \right) = \frac { 1 } { 2 } \left( \boldsymbol { R }_E ^ { T } \boldsymbol { F }_E + \left( \boldsymbol { R }_E ^ { T } \boldsymbol { F }_E \right) ^ { T } \right) - \boldsymbol { I } = \boldsymbol { S }_E - \boldsymbol { I }
\end{equation}
Substituting $ {\boldsymbol{\epsilon}}$ into equation \ref{eq:linear_elas} leads to the energy definition of corotational hyperelasticity:
\begin{equation}\label{eq:corot_S}
  \Psi_{CH} = \mu \| \boldsymbol{ S }_E - \boldsymbol { I } \| _ { F } ^ { 2 } + \frac { \lambda } { 2 } \operatorname { tr } ^ { 2 } ( \boldsymbol { S }_E - \boldsymbol { I } )
\end{equation}
Using rotation-invariance of the Frobenius norm:
\begin{equation}
  \Psi_{CH} = \mu \| \boldsymbol {F}_E  - \boldsymbol {R}_E \| _ { F } ^ { 2 } + \frac { \lambda } { 2 } \operatorname { tr } ^ { 2 } \left( \boldsymbol { R }_E ^ { T } \boldsymbol { F }_E - \boldsymbol { I } \right)
\end{equation}
Even more insight yields the relationship to their singular values $\sigma _ i$, also called the principal stretches:
$$\operatorname {tr}\left(\boldsymbol{S}\right) = \sum _ { i = 1 } \sigma _ { i } = \operatorname{tr}\left(\boldsymbol{\Sigma}_E\right)$$
$$\| \boldsymbol{S}_E \| _ { F }^2 = \sum _ { i = 1 } \sigma _ { i } ^ { 2 } = \| \boldsymbol{\Sigma}_E\|_{F}^2$$
$$\Rightarrow \| \boldsymbol{S}_E\boldsymbol{-I} \| _ { F }^2 = \|\boldsymbol{S}_E \| _ { F }^2 - 2 \operatorname{tr}(\boldsymbol{S}_E)  + \|\boldsymbol{I}\|_{F}^2 = \| \boldsymbol { \Sigma }_E - \boldsymbol { I } \| _ { F } ^ { 2 }$$
\begin{equation} \label{eq:corot_sing}
  \Psi_{CH}(\boldsymbol{\Sigma}_E) = \mu \| \boldsymbol { \Sigma }_E - \boldsymbol { I } \| _ { F } ^ { 2 } + \frac { \lambda } { 2 } \operatorname { tr } ^ { 2 } ( \boldsymbol { \Sigma }_E - \boldsymbol { I } )
\end{equation}
Equation \ref{eq:corot_sing} uses the diagonal matrix $\boldsymbol{\Sigma}_E$ containing the principal stretches typically acquired by the singular value decomposition $\boldsymbol{F}_E \boldsymbol{= U \Sigma}_E\boldsymbol{ V ^T }.$ Since the energy density in \ref{eq:corot_sing} is a function of only three (singular) values, which describe stretch/compression of the material, isotropy of the material is underlined.
\cite{ADAMS:ELASTICITY}
\subsubsection{Fixed Corotated Hyperelasticity}
Numerical Stepping algorithms\\
-> Newton Raphson scheme\\
-> Problem: Bad Primary contour\\
Benefit: Easier description in terms of Invariants\\
\cite{MPM:INVERT}
\subsection{Governing equations}
deriving the weak form
\subsubsection{Conservation of mass}
Let the Eulerian mass density be $_t\rho(_t\boldsymbol{x},t)$ and its (Lagrangian) pull back be $_0\rho(_0\boldsymbol{x},t)$.
After \ref{eq:pull_back_vol} they are related as:
\begin{equation} \label{eq:density_pull_back}
  \int _ {_tB _ { \epsilon }}_t\rho(_t\boldsymbol{x},t)d_t\boldsymbol{x} =   \int _ {_0B _ { \epsilon }} {^t_0J}_0\rho(_0\boldsymbol{x},t) d_0\boldsymbol{x}
\end{equation}
An open ball $ _ { 0 }B _ { \epsilon } $ in the reference configuration will have the same mass as its respective open ball $B_{\epsilon}^t$ in the current configuration. Keep in mind that both refer to a deformed state.

Conservation of mass dictates dictates that mass does not depend on motion or time. Only the space occupied by this mass may be more or less.
\begin{equation}
  \frac{d}{dt} \int _ {_tB _ { \epsilon }} _t\rho(_t\boldsymbol{x},t) d_t\boldsymbol{x} = 0
\end{equation}
Equivalently this can be formulated with the constant undeformed initial mass in Lagrangian view:
\begin{equation}\label{eq:lagr_mass}
  \left(\int _ {_tB _ { \epsilon }} _t\rho(_t\boldsymbol{x},t) d_t\boldsymbol{x} \stackrel{\text{\ref{eq:density_pull_back}}}{=} \right)
  \int _ {_0B _ { \epsilon }} {^t_0J}_0\rho(_0\boldsymbol{x},t) d_0\boldsymbol{x}=
  \int _ {_0B _ { \epsilon }} _0\rho(_0\boldsymbol{x},0)d_0\boldsymbol{x}.
\end{equation}
In Eulerian view the conservation of mass is more difficult to develop and starts with the Lagrangian view. Since the integrals do account for arbitrary volumes, they are left out in the following:
\begin{equation}\label{eq:euler_density_evol}
  \frac{\partial}{\partial t}(_0\rho^t_0J) = \frac{\partial _0\rho}{\partial t}{^t_0J} + \frac{\partial{^t_0J}}{\partial t} {_0\rho} = 0.
\end{equation}
The left side could be immediately pushed forward, the right side is harder:
\begin{equation}\label{eq:evol_jacobian}
  \frac{\partial{J}}{\partial t}
  = \frac{\partial{J}}{\partial {F_{ij}}} \frac{\partial {F_{ij}}}{\partial t}
  \stackrel{\text{\ref{eq:det_deriv},\ref{eq:evol_def_grad}}}{=} {J}{F}^{-1}_{ji}\frac{\partial v_i}{\partial x_k}F_{kj}
  = J \delta_{ik}\frac{\partial v_i}{\partial x_k} =  J \frac{\partial v_i}{\partial x_i}.
\end{equation}
The determinant differentiation rule can be shown by expressing the determinant with Laplace's expansion and applying the derivative on it:
\begin{equation}\label{eq:det_deriv}
  \frac{\partial J}{\partial F_{ij}} = \frac{\partial (F_{ik}\text{adj}(F)_{ki})}{\partial F_{ij}} =  \text{adj}(F)_{ji} = JF^{-1}_{ji}.
\end{equation}
The time-evolution of the deformation gradient is:
\begin{equation}\label{eq:evol_def_grad}
  \frac{\partial {{^t_0F_{ij}}}}{\partial t} =
  \frac{\partial}{\partial t}\frac{\partial {^t_0\phi_i}}{\partial _0x_j}(_0\boldsymbol{x},t) = \frac{\partial {_0v_i}}{\partial _0x_j}(_0\boldsymbol{x},t) =
  \frac{\partial {_tv_i}}{\partial _tx_k}(^t_0\phi(_0\boldsymbol{x},t),t)\frac{\partial {_tx_k}}{\partial {_0x_j}}(_0\boldsymbol{x},t).
\end{equation}
Pushing forward \ref{eq:euler_density_evol} with the result of \ref{eq:evol_jacobian} using the material derivative formulation \ref{eq:material_derivative}:
\begin{equation}
  \frac{D}{Dt}\rho(_t\boldsymbol{x},t) + \rho(_t\boldsymbol{x},t) \vec{\nabla} \cdot \boldsymbol{v}(_t\boldsymbol{x},t)=0
\end{equation}
Commonly used is the Nabla operator: $\vec { \nabla } = \left( \frac { \partial } { \partial x _ { 1 } } , \dots , \frac { \partial } { \partial x _ { n } } \right)$.
\cite{MPM:COURSE}
\subsubsection{Conservation of momentum}
Continuum forces are divided up into body and surface forces. A surface force acts upon the surface of the material $\partial _tB_\epsilon$. While a body force scales upon the volume of the material $_tB_\epsilon$. Conservation of momentum may then be expressed in a similar way to the conservation of mass as:
\begin{equation}
  \frac { d } { d t } \int _ {_tB _ { \epsilon}  } \rho ( _t\boldsymbol{x} , t ) \boldsymbol{v} ( _t\boldsymbol{x} , t ) d _t\boldsymbol{x} = \int _ { \partial _tB _ {\epsilon  } } \boldsymbol{\sigma} d_t\boldsymbol{A} (_t\boldsymbol{x} ) + \int _ { _tB_\epsilon } \boldsymbol{f} ^ {\text{body} } d _t\boldsymbol{x}.
\end{equation}
Where the assumption due to angular momentum conservation $\boldsymbol{\sigma}^T  = \boldsymbol{\sigma} $ out of the second part of this section has already been made for completion. Beginning with a mix out of Lagrangian and Eulerian view
$$\left(\frac { d } { d t } \int _ {_tB _ { \epsilon}  } \rho ( _t\boldsymbol{x} , t ) \boldsymbol{v} ( _t\boldsymbol{x} , t ) d _t\boldsymbol{x} \stackrel{\text{\ref{eq:eulerian_general}}}{=} \right)
\frac { d } { d t } \int _ {_0B _ { \epsilon}  } {^t_0J} \rho ( _0\boldsymbol{x} , t ) \boldsymbol{v} ( _0\boldsymbol{x} , t ) d _0\boldsymbol{x}$$
\begin{equation}
  \stackrel{\text{\ref{eq:euler_density_evol}}}{=}
  \int _ {_0B _ { \epsilon}  } {^t_0J} \rho ( _0\boldsymbol{x} , t ) \boldsymbol{a} ( _0\boldsymbol{x} , t ) d _0\boldsymbol{x}
  = \int _ { \partial _tB _ {\epsilon  } } \boldsymbol{\sigma} d_t\boldsymbol{A} (_t\boldsymbol{x} ) + \int _ { _tB_\epsilon } \boldsymbol{f} ^ {\text{body} } d _t\boldsymbol{x},
\end{equation}
where conservation of mass (equation \ref{eq:euler_density_evol}) was applied.
The Eulerian push-forward of the left side combined with the divergence theorem becomes:
\begin{equation}\label{eq:eul_transport}
  \int _ {_tB _ { \epsilon}  } \rho ( _t\boldsymbol{x} , t ) \boldsymbol{a} ( _t\boldsymbol{x} , t ) d _t\boldsymbol{x} =
  \int _ { \partial _tB _ {\epsilon } } \vec{\nabla} \cdot \boldsymbol{\sigma} d_t\boldsymbol{x}  + \int _ { _tB_\epsilon } \boldsymbol{f} ^ {\text{body} } d _t\boldsymbol{x}.
\end{equation}
The acceleration $_t\boldsymbol{a}$ is again defined due to the material derivative \ref{eq:material_derivative}. Thus the Eulerian momentum balance equation becomes:
\begin{equation}
  _t\rho \frac{D_t\boldsymbol{v}}{Dt} = \vec{\nabla} \cdot \boldsymbol{\sigma} +\boldsymbol{f} ^ {\text{body} }.
\end{equation}
There is a quantity left to be defined for the Lagrangian view. The Cauchy stress $\boldsymbol{\sigma}$ is defined in the current configuration. Pulling back the Cauchy stress leads to a stress measure named the first Piola Kirchhoff stress
\begin{equation}
  \int _ { \partial _tB _ {\epsilon  } } _t\boldsymbol{\sigma} d_t\boldsymbol{A} (_t\boldsymbol{x} )
  \stackrel{\text{\ref{eq:surface_integral}}}{=}
  \int _ { \partial _0B _ {\epsilon  } }  _0\boldsymbol{\sigma}\boldsymbol{F}^{-T} Jd_0\boldsymbol{A} (_0\boldsymbol{x} )=
  \int _ { \partial _0B _ {\epsilon  } }  \boldsymbol{P}d_0\boldsymbol{A} (_0\boldsymbol{x} ),
\end{equation}
denoted in the literature as:
\begin{equation}\label{eq:piola}
  \boldsymbol{P} =
  \frac{\partial \Psi}{\partial \boldsymbol{F}}=
  \boldsymbol{\sigma}\boldsymbol{F}^{-T}J.
\end{equation}
Summarized the Lagrangian view of the momentum equation with an initial momentum is ($^0_0J=1$):
\begin{equation}\label{eq:lagr_mom}
  _0\rho(_0\boldsymbol{x},0)_0\boldsymbol{a}(_0\boldsymbol{x},t)
= \vec{\nabla} \cdot \boldsymbol{P}(_0\boldsymbol{x},t) + {_0\boldsymbol{f}} ^ {\text{body}}(_0\boldsymbol{x},t) {^t_0J}.
\end{equation}
For the stress strain relationship $\boldsymbol{C}$ in chapter \ref{sec:linear_elasticty} as well as the start of this chapter conservation of angular momentum caused $\sigma_{ij} = \sigma_{ji}$. This can be shown as follows.
The description of angular momentum follows that of linear momentum where product rule generally applies $\left(\frac{D_t\boldsymbol{x}}{Dt} \times {_t\boldsymbol{v}} = {_t\boldsymbol{v}} \times {_t\boldsymbol{v}} = 0\right)$ :
\begin{equation}
  \int _ {_tB _ { \epsilon}  } _t\boldsymbol{x} \times \rho ( _t\boldsymbol{x} , t ) \boldsymbol{a} ( _t\boldsymbol{x} , t ) d _t\boldsymbol{x} = \int _ { \partial _tB _ {\epsilon  } }_t\boldsymbol{x} \times  \boldsymbol{\sigma}^T d_t\boldsymbol{A} (_t\boldsymbol{x} ) + \int _ { _tB_\epsilon }_t\boldsymbol{x} \times  \boldsymbol{f} ^ {\text{body} } d _t\boldsymbol{x}.
\end{equation}
In component form this becomes:
\begin{equation}\label{eq:gen_ang_mom}
  \int _ {_tB _ { \epsilon}  } \varepsilon_{ijk} \rho x_j a_k d _t\boldsymbol{x} = \int _ { \partial _tB _ {\epsilon  } } \varepsilon_{ijk} x_j \sigma_{mk} dA_m(_t\boldsymbol{x} ) + \int _ { _tB_\epsilon } \varepsilon_{ijk} x_j f_k ^ {\text{body} } d _t\boldsymbol{x}.
\end{equation}
The divergence theorem is again applied to the surface forces $\left(\vec{\nabla} = \frac{\partial}{\partial x_m}\right)$:
$$
\int _ { \partial _tB _ {\epsilon  } } \varepsilon_{ijk} x_j \sigma_{mk} dA_m (_t\boldsymbol{x} ) =
\int _ {_tB _ {\epsilon  } } \varepsilon_{ijk} \frac{\partial(x_j \sigma_{mk})}{\partial x_m} d_t\boldsymbol{x}
$$
\begin{equation}\label{eq:surface_ang_mom}
  = \int _ {_tB _ {\epsilon  } } \varepsilon_{ijk} \left(\delta_{jm} \sigma_{mk}+ x_j\frac{ \partial \sigma_{mk}}{\partial x_m}\right) d_t\boldsymbol{x}.
\end{equation}
The conservation of momentum (eq. \ref{eq:eul_transport}) can then be applied to the result of plugging \ref{eq:surface_ang_mom} into \ref{eq:gen_ang_mom} leaving only:
\begin{equation}
  \int _ {_tB _ {\epsilon  } } \varepsilon_{ijk} \sigma_{jk} d_t\boldsymbol{x} = 0.
\end{equation}
Leaving out the integral and multiplying by ${\varepsilon_{irs}}$ enables equation \ref{eq:compact_levi}. The Cauchy stress is constrained to
\begin{equation}
  \sigma_{ij} =\sigma_{ji}
\end{equation}
as assumed before. Note that $\boldsymbol{P}$ however is not constrained to be symmetric.
\subsubsection{Weak formulation}\label{sec:weak}
Before deriving the weak form an explanation of what it achieves is in order. The previous presented governing equations are written in the strong form: a solution to the equation needs to be exact on the whole domain (and is as such influenced by the whole domain in general). Such a solution can be found for simplified models analytically. These act as a ground truth to numerical methods like the material point method. Analytical methods of today can't handle complex problems: Numerical solutions try to overcome that hurdle.

The complete mathematical description of the weak formulation is beyond this thesis. Numeric books that discuess finite element methods will provide one (\cite{bathe2006finite}, \cite{dahmen2008numerik}). For simplicity: The weak formulation combined with Galerkin discretization restricts the globalility of the strong method due to so called 'test functions': $_0\boldsymbol{q}_h$ . A 'test function' generally only has limited support ($ _0\boldsymbol{q}_h\neq 0$ on a very small subset of the whole domain $\Omega^0$). This is mostly used to gather information on a local neighborhood.

The weak formulation requires an observation of the dot product. Consider the conservation of momentum in the strong form as formulated before (\ref{eq:lagr_mom}) as
\begin{equation}\label{eq:strong}
  _0\rho(_0\boldsymbol{x},0)_0\boldsymbol{a}(_0\boldsymbol{x},t)
  = \vec{\nabla} \cdot \boldsymbol{P}(_0\boldsymbol{x},t) + {_0\boldsymbol{f}} ^ {\text{body}}(_0\boldsymbol{x},t) {^t_0J}.
\end{equation}
Multiply both sides with the dot product of an arbitrary function $_0\boldsymbol{q}(\cdot,t):\Omega^0 \rightarrow \mathbb{R}^d$ and integrate over $\Omega^0$. If a solution solves the balance of \ref{eq:strong} then it also solves:
$$
\int _ { \Omega ^ { 0 } } _0q _ { i } ( _0\boldsymbol { x } , t ) \left(_0\rho (_0\boldsymbol{x} , 0 ) _0a _{ i } (_0\boldsymbol{x} , t ) - {_0\boldsymbol{f}} ^ {\text{body}}(_0\boldsymbol{x},t) {^t_0J}\right) d _0\boldsymbol{x}
$$
\begin{equation}
  =\int _ { \Omega ^ { 0 } } _0q _ { i } ( _0\boldsymbol { x } , t ) \frac{\partial P _ {ij}}{\partial x_j} ( _0\boldsymbol{x} , t ) d_0\boldsymbol{x}.
\end{equation}
With the help of partial integration in multiple dimension the derivative moves over to the test-function.
Reducing the order of derivatives by moving a derivative to the test function is the main motive of the weak form:
$$
\int _ { \Omega ^ { 0 } } \frac{\partial (_0q _ { i } ( _0\boldsymbol { x } , t ) P _ {ij} ( _0\boldsymbol{x} , t ))}{\partial _0x_j}
- \frac{\partial _0q _ { i }}{\partial _0x_j} ( _0\boldsymbol { x } , t ) P _ {ij}( _0\boldsymbol{x} , t )
d_0\boldsymbol{x}
$$
The divergence theorem allows to convert the first term to a boundary integral.
\begin{equation}
  \int _ { \partial \Omega ^ { 0 } } _0q _ { i } ( _0\boldsymbol { x } , t ) P _ {ij} ( _0\boldsymbol{x} , t)
  d_0\boldsymbol{A}(_0\boldsymbol{x})
  -\int _ { \Omega ^ { 0 } }  \frac{\partial _0q _ { i }}{\partial _0x_j} ( _0\boldsymbol { x } , t ) P _ {ij}( _0\boldsymbol{x} , t )
  d_0\boldsymbol{x}
\end{equation}
Mathematically the boundary integral serves as a boundary condition which is set by the specific problem (e.g. context of the simulation). Finally putting together the previous results gives the weak form of force balance in the Lagrangian view:
$$
\int _ { \Omega ^ { 0 } } _0q _ { i } ( _0\boldsymbol { x } , t ) \left(_0\rho (_0\boldsymbol{x} , 0 ) _0a _{ i } (_0\boldsymbol{x} , t ) - {_0f_i} ^ {\text{body}}(_0\boldsymbol{x},t) {^t_0J}\right) d _0\boldsymbol{x}
$$
\begin{equation} \label{eq:lagr_force_bal}
  = \int _ { \partial \Omega ^ { 0 } } _0q _ { i } ( _0\boldsymbol { x } , t ) P _ {ij} ( _0\boldsymbol{x} , t)
  d_0\boldsymbol{A}(_0\boldsymbol{x})
  -\int _ { \Omega ^ { 0 } }  \frac{\partial _0q _ { i }}{\partial _0x_j} ( _0\boldsymbol { x } , t ) P _ {ij}( _0\boldsymbol{x} , t )
  d_0\boldsymbol{x}.
\end{equation}
In the material point method stress computations are more naturally done in the current configuration. Pushing the equation forward to Eulerian view with the push forward $_t\boldsymbol{q}:\Omega^t \rightarrow \mathbb{R}^d$ of $_0\boldsymbol{q}$ is only a problem for the last term:
$$
\int _ { \Omega ^ { 0 } }  \frac{\partial _0q _ { i }}{\partial _0x_j} ( _0\boldsymbol { x } , t ) P _ {ij} d_0\boldsymbol{x}
\stackrel{\text{\ref{eq:piola}, \ref{eq:volume_integral}}}{=}
\int _ { \Omega ^ { 0 } }  \left({^t_0}F_{kj}\frac{\partial _tq _ { i }}{\partial _tx_k} ( _t\boldsymbol { x } , t )\right) \left({_t^0}F_{kj} \sigma _ {ik} {_0^tJ}\right) {_t^0J} d_t\boldsymbol{x}
$$
\begin{equation}  =  \int _ { \Omega ^ { t } } \frac{\partial _tq _ { i }}{\partial _tx_k} ( _t\boldsymbol { x } , t )\sigma _ {ik} d_t\boldsymbol{x}.
\end{equation}
This completes the Eulerian view to be:
$$
\int _ { \Omega ^ { t } } _tq _ { i } ( _t\boldsymbol { x } , t ) \left(_t\rho (_t\boldsymbol{x} , t) _ta _{ i } (_t\boldsymbol{x} , t ) - {_tf_i} ^ {\text{body}}(_t\boldsymbol{x},t)\right) d _t\boldsymbol{x}
$$
\begin{equation}\label{eq:eul_force_bal}
  = \int _ { \partial \Omega ^ { t } } _tq _ { i } ( _t\boldsymbol { x } , t ) \sigma _ {ij} d_tA_j(_t\boldsymbol{x}) -  \int _ { \Omega ^ { t } } \frac{\partial _tq _ { i }}{\partial _tx_k} ( _t\boldsymbol { x } , t )\sigma _ {ik} d_t\boldsymbol{x}.
\end{equation}
\cite{MPM:COURSE}
\cite{strang2007computational}
\cite{bathe2006finite}
\subsection{Material Point Method}\label{sec:mat_point}
The key idea of the material point method is to use (Lagrangian) particles as a consistent storage of material properties. All stress based forces are computed on a Eulerian grid however. This grid does not store any material properties and is therefore often referred to as a scratch pad.

As a corollary there needs to be a way to transfer information from a particle to the neighboring grid cells. This also induces switching from Lagrangian to Eulerian view. After stresses are computed there also needs to be a way to get back the relevant information from the grid to the particles. After the information is transferred back the particles are moved. This advection is typically hard to do in Eulerian/FEM-like methods and cause of a lot of problems down the development pipeline. In a Lagrangian view particle advection is trivial.

Its is very important that the two transfers as well as the grid solver are in compliance with all governing equations. While the grid solver will be derived from the weak form of the governing equation the transfers also need to be chosen in a way that also conserve the properties defined in them.
\cite{MPM:COURSE}
\subsubsection{Interpolation weights}
The choice of interpolation weights is flexible. Nevertheless a kernel $w(\boldsymbol{x})$ requires some important properties to be qualified for MPM:
\begin{enumerate}
  \item Partition of unity:
    \begin{equation}\label{eq:partition_unity}
      \sum _ { i } w \left(  { \boldsymbol{x} } -  { \boldsymbol{x} } _ { i } ^ { n } \right) & = 1.
    \end{equation}
  \item Identity relation:
    \begin{equation}
      \sum _ { i }  { \boldsymbol{x} } _ { i } ^ { n } w \left(  { \boldsymbol{x} } -  {\boldsymbol{ x} } _ { i } ^ { n } \right) & =  { \boldsymbol{x} }.
    \end{equation}
  \item $C^1$-continuity s.t. $\nabla w$ is continuous.
\end{enumerate}
As a reminder of chapter \ref{sec:notation}: $\boldsymbol{x}_p$ refers to a particle's position. $\boldsymbol{x}_i$ to a grid cell's position.
Often dyadic products of one-dimensional interpolation functions suffice
\begin{equation}
  w(\boldsymbol{x}-\boldsymbol{x}_i^n) = w_i^n(\boldsymbol{x}) = w\left(\frac{1}{h}\left(x-x_i^n\right)\right)w\left(\frac{1}{h}\left(y-y_i^n\right)\right)w\left(\frac{1}{h}\left(z-z_i^n\right)\right)
\end{equation}
\begin{equation}
  \nabla w_{i}^n(\boldsymbol{x})
  =\frac { 1 } {  { h } }
  \left(
    \begin{array} {l}
      w^{\prime} (\frac { 1 } {  { h } } ( x  - x _ { i }^n ))  { w }          ( \frac { 1 } {  { h } } (  { y }  -  { y } _ { i}^n  ) )   { w }         ( \frac { 1 } {  { h } } ( z  - z _ { i }^n ) \\
      w(\frac{1} {  { h } } ( x  - x _ { i }^n ))               { w }^{\prime} ( \frac { 1 } {  { h } } (  { y }  -  { y } _ { i}^n  ) )   { w }         ( \frac { 1 } {  { h } } ( z  - z _ { i }^n ) \\
      w(\frac{1} {  { h } } ( x  - x _ { i }^n ))               { w }          ( \frac { 1 } {  { h } } (  { y }  -  { y } _ { i}^n  ) )   { w }^{\prime}( \frac { 1 } {  { h } } ( z  - z _ { i }^n ) \\
    \end{array}
  \right),
\end{equation}
where $h$ is the grid spacing (of a uniform grid). An interpolation function often employed is a cubic B-spline ($C^2$):
\begin{equation}\label{eq:cubic_weights}
  w(x) = \left\{ \begin{array} { l l } { \frac { 1 } { 2 } | x | ^ { 3 } - | x | ^ { 2 } + \frac { 2 } { 3 } } & { 0 \leqslant | x | < 1 } \\ { \frac { 1 } { 6 } ( 2 - | x | ) ^ { 3 } } & { 1 \leqslant | x | < 2 } \\ { 0 } & { 2 \leqslant | x | } \end{array} \right. .
\end{equation}
Since these function are used to weight (or filter) particles a shortening in notation may be employed as $ w_{ip}^n = w(\boldsymbol{x}_p^n-\boldsymbol{x}_i^n)$.
\cite{MPM:APIC}\cite{MPM:COURSE}
\subsubsection{Mass transfer}
Each material point will be assigned an initial volume $_0V_p$ as well as a initial mass $_0m_p$. The volume the material point occupies may change in time due to eq. \ref{eq:j}: ${^t_0}J _0V_p = {_tV_p}$. But due to conservation of mass \ref{eq:lagr_mass} it will have a constant, initial mass associated with it. I.e. there will only be a transfer to the grid and no transfer back.
A transfer of mass to the grid may then be expressed as:
\begin{equation}\label{eq:mpm:mass}
  m_i = \sum_p w_{ip}m_p.
\end{equation}
$\sum_i m_i =\sum_p m_p$ is a complete prove this fulfills the conservation of mass. Remember there is no transfer back. In doing so no information can be lost on the particles. Proving that the mass transfer to the grid is conserving is enough. The stress based-solver may manipulate this information further (mass-lumping strategies).
\begin{equation}
  \sum_i m_i
  \stackrel{\text{\ref{eq:mpm:mass}}}{=}
  \sum _i \sum_p w_{ip} m_p =
  \sum _p m_p \sum_i w_{ip}
  \stackrel{\text{\ref{eq:partition_unity}}}{=}
  \sum_p m_p
\end{equation}
\cite{MPM:APIC}\cite{MPM:COURSE}
\subsubsection{APIC transfers}
The momentum transfer round trip could be defined as:
\begin{enumerate}
  \item Particle to grid momentum transfer:
    \begin{equation}\label{eq:lin_p2g}
      (m\boldsymbol{v})_i^n = \sum_p w_{ip}m_p\boldsymbol{v}^n_p.
    \end{equation}
  \item Factoring out mass:
    \begin{equation}
      \boldsymbol{v}_i^n = \frac{(m\boldsymbol{v})_i^n}{m_i^n}.
    \end{equation}
  \item Coupled with either ($\alpha \in \{0,1\}$) or a combination ($\alpha \in ]0;1[$) of:
    \begin{equation}
      \boldsymbol{v}_p^{n+1} = \alpha\boldsymbol{v}_{p,{PIC}}^{n+1} + (1-\alpha)\boldsymbol{v}_{p,{FLIP}}^{n+1}
    \end{equation}
    \begin{equation}\label{eq:PIC}
      \boldsymbol{v}_{p,{PIC}}^{n+1} = \sum_i w_{ip}\boldsymbol{v}_i^{n+1}.
    \end{equation}
    \begin{equation}\label{eq:FLIP}
      \boldsymbol{v}_{p,{FLIP}}^{n+1} = \boldsymbol{v}_p^{n} + \sum_i w_{ip}(\boldsymbol{v}_i^{n+1}-\boldsymbol{v}_i^{n+1}).
    \end{equation}
\end{enumerate}
While $PIC$-Transfers are very stable they suffer from excessive (energy) dissipation due to double interpolating on the whole quantity \ref{eq:lin_p2g},\ref{eq:PIC}. This causes a heavy loss in angular momentum and velocity modes.
$FLIP$-Transfers avoid dissipation and loss of angular momentum by only updating the velocity with a difference \ref{eq:FLIP}. However some velocity modes are also not recognized on the grid and may cause unpredictable and unstable behavior in following steps. Therefore often a combination of both is taken.

$APIC$ builds on top of the very stable $PIC$-transfers and effectively only adds an extra term of the Taylor series to increase accuracy. This extra term $\boldsymbol{C}_p$ may be in short just referred to as the velocity derivative. The local velocity field around a particle may then be characterized by the affine function $\boldsymbol{v}(\boldsymbol{x}) = \boldsymbol{C}_p(\boldsymbol{x}-\boldsymbol{x}_p)$.

Motivated by the theory of angular momentum and moment of inertia one can define a quantity
\begin{equation}
\boldsymbol { D } _ { p } ^ { n } = \sum _ { i } w _ { i p } ^ { n } ( \boldsymbol { x } _ { i } ^ { n } - \boldsymbol { x } _ { p } ^ { n } ) ( \boldsymbol { x } _ { i } ^ { n } - \boldsymbol { x } _ { p } ^ { n } ) ^ { T },
\end{equation}
which is similar to the classically known inertia tensor:
\begin{equation}
  \boldsymbol{I} _ { p } = - \sum _ { i } m _ { i } [\boldsymbol{x} _ { i }-\boldsymbol{x}_{p}][\boldsymbol{x} _ { i }-\boldsymbol{x}_{p}]^T
\end{equation}
$$
=
\sum _ { i } m _ { i }((\boldsymbol{x} _ { i }-\boldsymbol{x}_{p})^T(\boldsymbol{x} _ { i }-\boldsymbol{x}_{p})\boldsymbol{I} -(\boldsymbol{x} _ { i }-\boldsymbol{x}_{p})(\boldsymbol{x} _ { i }-\boldsymbol{x}_{p})^T)
$$
Bearing in mind that $\boldsymbol{D}_p^n$ does not include a mass and is defined for an affine motion instead of an angular motion, where $[a]_{\alpha\gamma} = \varepsilon_{\alpha\beta\gamma}a_{\beta}$ is the cross-product matrix and $\boldsymbol{I}$ denotes the identity matrix.
In classical mechanics the angular velocity $\boldsymbol{\omega_p}$ can be then described using the inertia tensor $\boldsymbol{I}_p$ with the help of the angular momentum $\boldsymbol{L}_p$:
\begin{equation}
  \boldsymbol{\omega}_p = \boldsymbol{I}_p^{-1} \boldsymbol{L}_p.
\end{equation}
This motivates the velocity derivative to be equally defined by a similar relationship, where $\boldsymbol{B}^n_p$ holds momentum information.
\begin{equation}
  \boldsymbol{C}^n_p = (\boldsymbol{D}_p^n)^{-1} \boldsymbol{B}^n_p.
\end{equation}
The transfers of the $APIC$-scheme are then summarized:
\begin{enumerate}
  \item Particle to grid:
    \begin{equation}\label{eq:apic_mom_p2g}
    (m\boldsymbol{v})^n_i = \sum_p w^n_{ip}m_p (\boldsymbol { v } _ { p } ^ { n } + \boldsymbol { B } _ { p } ^ { n } ( \boldsymbol { D } _ { p } ^ { n } ) ^ { - 1 } ( \boldsymbol { x } _ { i } ^ { n } - \boldsymbol { x } _ { p } ^ { n } ) )
\end{equation}
  \item Factoring out mass:
    \begin{equation}
      \boldsymbol{v}_i^n = \frac{(m\boldsymbol{v})_i^n}{m_i^n}.
    \end{equation}
  \item Grid to particle transfer (in a $PIC$-manner), where in contrast the new particle position $\boldsymbol{x}_p$ also needs to be interpolated:
    \begin{equation}
      \boldsymbol{x}_{p}^{n+1} = \sum_i w_{ip}\boldsymbol{x}_i^{n+1}
    \end{equation}
    \begin{equation}
      \boldsymbol{v}_{p}^{n+1} = \sum_i w_{ip}\boldsymbol{v}_i^{n+1}
    \end{equation}
    $$
    {^-}\Delta \boldsymbol{x} = \boldsymbol { x } _ { i } ^ { n } - \boldsymbol { x } _ { p } ^ { n } +   \boldsymbol { x }_ { i } ^ { n + 1 } - \boldsymbol { x } _ { p } ^ { n + 1 },
    \quad {^+}\Delta \boldsymbol{x} = \boldsymbol { x } _ { i } ^ { n } - \boldsymbol { x } _ { p } ^ { n } -  { \boldsymbol { x } } _ { i } ^ { n + 1 } + \boldsymbol { x } _ { p } ^ { n + 1 }
    $$
\begin{equation}\label{eq:apic_mom_g2p}
  \boldsymbol { B } _ { p } ^ { n + 1 } = \frac { 1 } { 2 } \sum _ { i } w _ { i p } ^ { n } (\boldsymbol { v }_ { i } ^ { n + 1 } ({^-}\Delta \boldsymbol{x}) ^ { T }) {+}  {^+}\Delta \boldsymbol{x} ( { \boldsymbol { v } } _ { i } ^ { n + 1 } ) ^ { T }).
\end{equation}

\end{enumerate}
For a full proof that these transfers preserve linear and angular momentum consult \cite{MPM:APIC}. For the choice of dyadic products of cubic b-splines (\ref{eq:cubic_weights}) $\boldsymbol{D}_p$ takes on the simple form:
\begin{equation}
\boldsymbol{D}_p^n = \frac { 1 } { 3 } h ^ { 2 } \boldsymbol { I }.
\end{equation}
A simple proof (Appendices: \ref{app:dp_proof}) cancelling out the numerous polynomials can be done for instance using SymPy (\cite{Sympy}).\cite{MPM:APIC}\cite{MPM:OLD_APIC}
\subsubsection{CFL condition}
The CFL condition is prominent for FEM-like methods: For a stable integration a particle should not travel father than the grid spacing $h$ in a discrete time-step $\Delta t$. $\Delta t$ is thus limited by:
\begin{equation}
  \Delta t \leq \frac{h}{\|\boldsymbol{v}^n_i\|_2}.
\end{equation}
Assuming $\|\boldsymbol{x}_i^n -\boldsymbol{x}_p^n\| \leq \kappa h$, where $\kappa$ is determined by the interpolation stencil support (cubic 3D: $\kappa = 2\sqrt{3}$) and additionally assuming $\boldsymbol{D}_p^n = k\boldsymbol{I} \Rightarrow (\boldsymbol{D}_p^n)^{-1} = \frac{1}{k}\boldsymbol{I}$ (cubic 3D: $k=\frac{1}{3}h^2$).
$\|\boldsymbol{v}^n_i\|_2$ can be estimated on the particles. Typically the number of particles is lower. Given Eq. \ref{eq:apic_mom_p2g}:
$$
\|\boldsymbol{v}^n_i\|_2 \leq \frac{1}{m_i^n}\left(\sum _ { p } w _ { i p } ^ { n } m _ { p } \| \boldsymbol { v } _ { p } ^ { n } \|_2 + \sum _ { p } w _ { i p } ^ { n } m _ { p } \| \boldsymbol { B } _ { p } ^ { n } \| _ { F } \| ( \boldsymbol { D } _ { p } ^ { n } ) ^ { - 1 } ( \boldsymbol { x } _ { i } ^ { n } - \boldsymbol { x } _ { p } ^ { n } ) \|_2\right)
$$
\begin{equation}
\leq \max _ { p } ( \| \boldsymbol { v } _ { p } ^ { n } \|_2 + \frac { \kappa } { k } \Delta x \| \boldsymbol { B } _ { p } ^ { n } \| _ { F } )
\end{equation}
\cite{MPM:APIC}
\subsection{Discretization}
The weak form of the force-balance in (\ref{eq:lagr_force_bal},\ref{eq:eul_force_bal}) implies the following for MPM preferable description:
\begin{equation} \label{eq:weak_mpm}
  \int _ { \Omega ^ { 0 } } (_0q _ \alpha) (_0\rho_0) (_0a _\alpha)  d _0\boldsymbol{x}= \int _ { \partial \Omega ^ { t^n } } _tq _ \alpha \sigma _ {\alpha\beta} d_tA_\beta(_t\boldsymbol{x}) -  \int _ { \Omega ^ { t^n} } \frac{\partial _tq _ \alpha}{\partial _tx_\beta} \sigma _ {\alpha\beta} d_t\boldsymbol{x}.
\end{equation}
The boundary integral is mostly due to collisions and will be ignored for now. \cite{MPM:OPTIMI_INTEGR} discusses level set collisions due to constraint collisions, object penalty collision and penalty self-collisions. An handling of collision would need to take them into account when solving the equation. A simple though less accurate method is to process collisions separately in a typical computer graphics manner, which is assumed for now.
\subsubsection{Discretize time}
Any integrator conserving linear and angular momentum could be used to discretize time. The class of time integrators used here are characterized by \begin{equation}\label{eq:midpoint}
  \frac{y ^ { n + 1 } - y ^ { n }}{ \Delta t} = f^{n+\lambda} = f \left(t^n+\lambda\Delta t, (1-\lambda) y ^ { n } +\lambda y^{n+1}\right)
\end{equation}
for a differential equation of order one:
\begin{equation}
  \frac{\partial y}{\partial t}( t ) = f (t,y(t)) , \quad y (0) = y _ { 0 }.
\end{equation}
A prominent member of this class is the implicit midpoint rule ($\lambda =\frac{1}{2}$). Replacing the Lagrangian acceleration $_0a_\alpha$ in eq. \ref{eq:weak_mpm} with the left side of \ref{eq:midpoint} using velocity, taking care of the right side and pushing forward to Eulerian view:
\begin{equation}\label{eq:time_disc}
  \frac{1}{\Delta t} \int _{ \Omega^{t^n}}(_tq_\alpha)(_t\rho)({_tv_\alpha^{n+1}}-{_tv_\alpha^{n}}) d_t\boldsymbol{x} =
  -  \int _ { \Omega ^ { t^n} } \frac{\partial _tq _ \alpha}{\partial _tx_\beta} \sigma _ {\alpha\beta}^{n+\lambda} d_t\boldsymbol{x}.
\end{equation}
\subsubsection{Discretize space}
A Galerkin discretization brings all spatial terms of equation \ref{eq:time_disc} to a finite-dimensional space: $\boldsymbol{q} \rightarrow \boldsymbol{q}_h$. To not further clutter up the notation, the $h$ will be omitted. This will replace $q_\alpha, v^n_\alpha , v_\alpha^{n+1}$ with their finite-dimensional grid-based interpolants:
\begin{equation}
  {_t q } _ { \alpha } ^ {  { n } } =  ({_t q } _ {  { i } \alpha } ^ {  { n } })  ({_t w } _ { i }) , \quad _tv _ { \alpha } ^ {  { n } } = ({_tv _ {  { j\alpha } } ^ {  { n } }} )( {_t w } _ {  { j } }) , \quad {_tv _ { \alpha } ^ {  { n } + 1 }} = ({_tv _ {  { j } \alpha } ^ {  { n } + 1 }}) ({_t w } _ {  { j } }).
\end{equation}
Further chapter \ref{sec:weak} mentions that $\boldsymbol{q}$ can be chosen arbitrarily. The Galerkin discretization of a $d$-dimensional space with $m$ grid nodes therefore uses the standard basis functions $e_1,e_2, ... ,e_{d \times m}$. Due to the scalar-product $d\times m$ equations would need to be solved:
\begin{equation}\label{eq:galerkin}
  \frac{1}{\Delta t} \int _{ \Omega^{t^n}} ({ _tw } _ {i  })(_t\rho)({_t w } _ { j  })({_tv_{j\alpha}^{n+1}}-{_tv_{j\alpha}^{n}}) d_t\boldsymbol{x} =
 - \int _ { \Omega ^ {  t^ n } }   \frac{\partial{_t w } _ { {i  }}}{\partial_tx_\beta }  \sigma _ {{ \alpha } \beta }  { d } \boldsymbol { x }.
\end{equation}
A mass matrix can be factored out as:
\begin{equation}
  m_{ij}^n = \int _{ \Omega^{t^n}} {_t w } _ {i  }(_t\rho){_t w } _ { j  } d_t\boldsymbol{x}.
\end{equation}
The Lagrangian pull-back relates this to the initial density in the Lagrangian view and discretizing the integral with the initial time-invariant particle mass $m_p \approx V_p^0\rho(_0x_p,0)$:
\begin{equation}
m_{ij}^n = \int _{ \Omega^{t^0}} ({_tw_i})(_0\rho_0)({_tw} _ { j  }) d_0 \boldsymbol{x} \approx \sum _ {  { p } }  { m } _ {  { p } }  { w } _ {  { i } } (\boldsymbol { x } _ {  { p } } )  { w } _ {  { j } } ( \boldsymbol { x } _ {  { p } } ).
\end{equation}
This matrix is symmetric positive semi-definite (since mass is positive). Numerically this matrix is mostly not used as is due to possibility of it being singular. This is solved commonly due to a mass lumping strategy. Replace $m^n_{ii}$ with the $i$-th row sum to get:
\begin{equation}\label{eq:mass_discr}
\sum _ {  { p } }  { m } _ {  { p } }  { w } _ {ip}   w_{jp}
\stackrel{\text{\ref{eq:partition_unity}}}{\approx}
\sum_p m_p w_{ip}
\stackrel{\text{\ref{eq:mpm:mass}}}{=}
m_i^n,
\end{equation}
where partition of unity $\sum_j w_{jp} = 1$ is used. This is exactly the mass transfer as in eq. \ref{eq:mpm:mass}, s.t. no further assembling of a mass matrix is needed.
Discretizing the right side of \ref{eq:galerkin} with an estimated per particle stress $\boldsymbol{\sigma}_p^{n+\lambda}$:
\begin{equation}\label{eq:stress_discr}
\int _ { \Omega ^ {  t^ n } }   \frac{\partial{_t w } _ { {i  }}}{\partial_tx_\beta }  \sigma _ {{ \alpha } \beta }  { d } \boldsymbol { x } \approx
\sum _ { p } (\sigma _ { p }^{n+\lambda}) _ { \alpha \beta } \frac{{ \partial w } _ { {ip}}^n}{ \partial x_\beta }  V _ { p } ^ { n }.
\end{equation}
Setting in equation \ref{eq:mass_discr} and \ref{eq:stress_discr} into \ref{eq:galerkin} summarizes the space discretization as:
\begin{equation}\label{eq:space_discr}
  \frac{1}{\Delta t} (({m^n\boldsymbol{v}^{n+1}})_i-({m^n\boldsymbol{v}^n})_i) =
  -\sum _ { p } \boldsymbol{\sigma} _ { p }^{n+\lambda} \nabla w_{ip}^n V _ { p } ^ { n }
  = \boldsymbol{f}_i^{n+\lambda}.
\end{equation}
The momentum change of the left side is by construction equal to a (grid node) force.\\
Given that the material point method keeps track of the deformation by a deformation gradient. Each particle will have one associated with it for the deformation of its local neighborhood $\boldsymbol{F}^n_p$. Based on this one may also gain a volume change measure around the particle as $J^n_p = \text{det}(\boldsymbol{F}^n_p)$. Starting with an initial volume of a particle $V_p^0$ the volume may be tracked in time by:
\begin{equation}\label{eq:volume_discr}
  V^n_p \stackrel{\text{\ref{eq:j}}}{\approx} V_p^0J^n_p.
\end{equation}
In eq. \ref{eq:piola} an alternate measure for the stress by the first Piola Kirchhoff stress. The results of \ref{eq:space_discr} may therefore equally expressed by it:
$$
\boldsymbol{f}^{n+\lambda}_i \stackrel{\text{\ref{eq:piola},\ref{eq:volume_discr}}}{=}
- \sum_p \frac{1}{J^n_p}\boldsymbol{P}^{n+\lambda}_{p}(\boldsymbol{F}^{n}_{p})^T \nabla w_{ip}V^0_pJ^n_p
$$
\begin{equation}\label{eq:force_disc}
  = - \sum_p \boldsymbol{P}^{n+\lambda}_{p}(\boldsymbol{F}^{n}_{p})^T \nabla w_{ip}V^0_p.
\end{equation}
\cite{MPM:COURSE} \cite{MPM:APIC} \cite{bathe2006finite}
\subsubsection{Deformation gradient evolution}
In eq. \ref{eq:evol_def_grad} the evolution of the deformation gradient is shown to be:
\begin{equation}
  \frac{\partial ^t_0\boldsymbol{F}}{\partial t} =  \nabla{_0\boldsymbol{v}}(_0\boldsymbol{x},t).
\end{equation}
Discretizing the Lagrangian deformation gradient in time with eq. \ref{eq:midpoint} results in:
\begin{equation}
  \frac{\boldsymbol{F}^{n+1}_p + \boldsymbol{F}^{n}_p}{\Delta t} =  \nabla_0\boldsymbol{v}^{n+\lambda}(_0\boldsymbol{x}).
\end{equation}
Pushing the right side forward to Eulerian view
\begin{equation}
  \frac{\boldsymbol{F}^{n+1}_p + \boldsymbol{F}^{n}_p}{\Delta t} =  \nabla_t\boldsymbol{v}^{n+\lambda}(_t\boldsymbol{x})^t_0\boldsymbol{F} = \nabla_t\boldsymbol{v}^{n+\lambda}(_t\boldsymbol{x})\boldsymbol{F}^n_p
\end{equation}
and further applying the Galerkin discretization
\begin{equation}
  (_tv^{n+\lambda})_\alpha = (v_{i}^{n+\lambda})_\alpha w_i \Rightarrow \frac{\partial (_tv^{n+\lambda})_\alpha}{\partial x_\beta} =(v_i^{n+\lambda})_\alpha\frac{\partial w_i}{\partial x_\beta}
\end{equation}
leads to the final update rule for the deformation gradient:
\begin{equation}\label{eq:evol_def_grad_disc}
\boldsymbol{F}^{n+1}_p = \left( \boldsymbol{I} + \Delta t\sum_i \boldsymbol{v}_i^{n+\lambda}({\nabla w_{ip}})^T \right)\boldsymbol{F}^{n}_p.
\end{equation}
The discretization of the position will also be of need to advance the particles and weight them back:
\begin{equation}  \frac{\partial _t\boldsymbol{x}}{\partial t} = {_t\boldsymbol{v}} \Rightarrow \frac{\boldsymbol{\hat{x}}_i^{n+1}
  - \boldsymbol{x}_i^{n}}{\Delta t} = \boldsymbol{v}_i^{n+\lambda}.
\end{equation}
The grid position $\boldsymbol{\hat{x}}_i^{n+1}$ does not correspond to an actual deformation. The grid never actually gets deformed (unlike in FEM-methods). Therefore the discretized evolution of the deformation gradient  \ref{eq:evol_def_grad_disc} is directly a function of $\boldsymbol{\hat{x}}$. For the point $\boldsymbol{\hat{x}}_i^{n+1}$ this becomes:
\begin{equation}\label{eq:evol_def_grad_disc_x}
  \boldsymbol{\hat{F}}^{n+1}_p(\boldsymbol{\hat{x}}_i^{n+1}) =  \left( \boldsymbol{I} + \sum_i (\boldsymbol{\hat{x}}_i^{n+1} - \boldsymbol{x}_i^{n})({\nabla w_{ip}})^T \right)\boldsymbol{F}^{n}_p.
\end{equation}
As part of the class of time integrators in use (\ref{eq:midpoint}) a function of $\boldsymbol{x}_i$ gets evaluated at an in-between point given by:
\begin{equation}\label{eq:midpoint_x}
  \boldsymbol{x}_i^{n+\lambda} = \lambda \boldsymbol{x}_i^{n+1} + (1-\lambda)\boldsymbol{x}_i^n.
\end{equation}
Plugging this point into \ref{eq:evol_def_grad_disc_x} leads to the following generalization:
$$\boldsymbol{\hat{F}}^{n+\lambda}_p(\boldsymbol{x}_i^{n+\lambda}) = \left( \boldsymbol{I} + \lambda \sum_i (\boldsymbol{\hat{x}}_i^{n+1} - \boldsymbol{x}_i^{n})({\nabla w_{ip}})^T \right)\boldsymbol{F}^{n}_p
  $$
  \begin{equation} \label{eq:def_grad_lambda}
  = (1-\lambda)\boldsymbol{F}^n_p + \lambda \boldsymbol{F}^{n+1}_p
\end{equation}
This
\cite{MPM:COURSE}
\subsubsection{Grid nodal forces}
The notion of a total elastic potential energy function $\Psi$ was introduced in chapter \ref{sec:cor_hyper}. The MPM approximation to this function can be defined by:
\begin{equation}\label{eq:energy_discr}
  e(\hat{\boldsymbol{x}}) = \sum_pV^0_p \Psi(\hat{\boldsymbol{F}}_{Ep}(\hat{\boldsymbol{x}})).
\end{equation}
The evolution of the deformation gradient \ref{eq:evol_def_grad_disc_x} for a general $\boldsymbol{\hat{x}}_i$  is necessary
$$\frac{\partial \hat{F}_{\omega\beta}}{\partial \hat{x}_\alpha}
= \delta_{\omega \alpha}
\frac{\partial w_{ip}}{\partial x_\gamma}F_{\gamma\beta} = \delta_{\omega \alpha}F_{\gamma\beta} \frac{\partial{w_{ip}}}{\partial x_\gamma}$$
for the spatial derivative of the potential $e(\boldsymbol{\hat{x}})$. This is just the force created by elastic stresses out of eq. \ref{eq:force_disc}:
$$
  \frac{\partial e}{\partial \hat{x}_{i\alpha}}(\hat{\boldsymbol{x}})
  = \sum_p V^0_p \frac{\partial \Psi}{\partial \hat{F}_{\omega\beta}}(\hat{\boldsymbol{F}}_{Ep})\frac{\partial \hat{F}_{\omega\beta}}{\partial \hat{x}_\alpha}
  $$
  \begin{equation}\label{eq:nodal_force}
  = \sum_p V^0_p P_{\alpha\beta}(\hat{\boldsymbol{F}}_{Ep})F_{\gamma\beta}\frac{\partial w_{ip}}{\partial x_\gamma} = -\hat{f}_{i\alpha}.
\end{equation}
The nodal force can be also described in terms of the Cauchy stress:
\begin{equation}
  \boldsymbol{\hat{f}}_i = - \sum_p V^n_p \boldsymbol{\sigma}_p(\boldsymbol{\hat{F}}_{Ep})\nabla{w^n_{ip}}.
 \end{equation}
Due to eq. \ref{eq:def_grad_lambda} the stress computation is summarized for the class of functions in use as:
\begin{equation}
  \boldsymbol{P}^{n+\lambda}(\hat{\boldsymbol{F}}_{Ep}) = \boldsymbol{P}(\hat{\boldsymbol{F}}^{n+\lambda}_{Ep}),
  \quad
  \boldsymbol{\sigma}^{n+\lambda}(\hat{\boldsymbol{F}}_{Ep}) = \boldsymbol{\sigma}(\hat{\boldsymbol{F}}^{n+\lambda}_{Ep}).
\end{equation}
\cite{MPM:COURSE}\cite{MPM:APIC}
\subsubsection{Symplectic midpoint scheme}
Starting from the last update on the grid which is typically the position with eq. \ref{eq:midpoint} the general midpoint scheme ($\lambda=\frac{1}{2}$) is:
\begin{equation}\label{eq:vel_midpoint}
  \boldsymbol{\hat{x}}_i^{n+1}   =\boldsymbol{x}_i^{n} + \Delta t \boldsymbol{v}_i^{n+\frac{1}{2}}.
\end{equation}
Due to \ref{eq:space_discr} a velocity update can be put together as:
\begin{equation}\label{eq:force_midpoint}
\boldsymbol{\hat{v}}^{n+1}_i
= \boldsymbol{v}^n_i+ \frac{\Delta t}{m_i^n}\boldsymbol{f}_i^{n+\frac{1}{2}}.
\end{equation}
A variable of $n+\frac{1}{2}$ then gets evaluated at the midpoint (\ref{eq:midpoint_x}):
\begin{equation}
  \boldsymbol{f}^{n+\frac{1}{2}}_i =  \boldsymbol{f}_i\left(\frac{\boldsymbol{x}_i^n + \boldsymbol{\hat{x}}_i^{n+1}}{2}\right).
\end{equation}
The modified energy conserving implicit midpoint scheme from \cite{GONZALEZ} for the Material Point Method differs by the use of a trapezoidal approximation of $\boldsymbol{v}_i^{n+\frac{1}{2}}$:
\begin{equation}\label{eq:trapezoidal}
  \boldsymbol{v}_i^{n+\frac{1}{2}} \approx \frac{\boldsymbol{\hat{v}}_i^{n+1} + \boldsymbol{v}_i^{n}}{2}.
\end{equation}
The trapezoidal rule has the same order of error $O(\Delta t^2)$ as the implicit midpoint scheme. This modification allows for a more direct one-step scheme as shown in the following. Plugging $\boldsymbol{x}_i^{n+1}$ of eq. \ref{eq:vel_midpoint} into \ref{eq:force_midpoint}:
\begin{equation}
  \boldsymbol{h}(\boldsymbol{\hat{v}}_i^{n+1}) = m_i^n \frac{\boldsymbol{\hat{v}_i}^{n+1}-\boldsymbol{v}_i^n}{\Delta t} - \boldsymbol{f}_i\left(\boldsymbol{x}_i^n + \frac{\Delta t}{4} (\boldsymbol{\hat{v}}_i^{n+1} + \boldsymbol{v}_i^{n})\right) = 0.
\end{equation}
And substituting
One can recast this method back to an energy function by integrating:
\begin{equation}
  E(\boldsymbol{v}_i) = \sum_i \frac{m_i^n}{8} \|\boldsymbol{v}_i - \boldsymbol{v}_i^n\|^2_2 + e(\boldsymbol{x}_i^n + \frac{\Delta t}{4}(\boldsymbol{v}_i + \boldsymbol{v}_i^n)),
\end{equation}
where $e$ is just the discretized elastic potential energy out of \ref{eq:energy_discr}. In general this is a optimization objective that needs minimizing to solve for the updated velocities. Recasting allows solving in a general scheme by an optimization integrator.

In general starting off with an energy description is a more physical approach of the problem. The first term can be identified clearly as the kinetic energy. Moreover it easily allows adding potential terms for gravity or collision \cite{MPM:OPTIMI_INTEGR}. Or modifying the energy function altogether based off for instance the fundamental state of matter: as an example the phase transition to and physics of a liquid \cite{MPM:PHASE_CHANGE}.
The analysis of minimizing the objective is equivalent to finding the zero crossing of the derivative:
\begin{equation}
  \argmin_{\forall \boldsymbol{v}_i}(E(\boldsymbol{v}_i)) \Leftrightarrow g(\boldsymbol{v}_i) = \frac{\partial E}{\partial \boldsymbol{v}_i} = 0.
\end{equation}
Since the objective from the start was minimizing $\boldsymbol{E}$ to find $\boldsymbol{v}_i$ the scale of this function can be chosen arbitrarily, i.e. a zero crossing does not scale. The scaling here can be identified as:
\begin{equation}
  \boldsymbol{g}(\boldsymbol{v}_i) = \frac{\Delta t}{4} h(\boldsymbol{v}_i) = m_i^n \frac{\boldsymbol{v_i}-\boldsymbol{v}_i^n}{4} -\frac{\Delta t}{4} \boldsymbol{f}_i\left(\boldsymbol{x}_i^n + \frac{\Delta t}{4} (\boldsymbol{v}_i + \boldsymbol{v}_i^{n})\right).
\end{equation}
\cite{MPM:COURSE}\cite{MPM:APIC}
\subsection{Newton's Method}
\newcommand{\var}[1]{{\ttfamily#1}}% variable
\begin{algorithm}[t]
  \caption{Conjugate gradient}\label{alg:conj_grad}
  \begin{algorithmic}[1]
    \Procedure{CONJUGATE-GRADIENT}{$H,x,f$}
    \State $\boldsymbol{x} \gets \Call{InitialGuess}$
    \State $\boldsymbol{Hx} \gets \Call{ComputeHp}{x}$
    \State $\boldsymbol{r}\gets \boldsymbol{f} - \boldsymbol{Hx}$
    \State $\boldsymbol{p}\gets \boldsymbol{r}$
    \State $\gamma \gets \langle \boldsymbol { r } , \boldsymbol { r } \rangle$
    \Repeat
      \State $\boldsymbol{Hp} \gets \Call{ComputeHp}{p}$
      \State $\boldsymbol { s } \gets \boldsymbol { H } \boldsymbol { p }$
      \State $\alpha \gets \frac { \gamma } { \langle \boldsymbol { p } , \boldsymbol { s } \rangle }$
      \State $\boldsymbol { x } \gets \boldsymbol { x } + \alpha \boldsymbol { p }$
      \State $\boldsymbol { r } \leftarrow \boldsymbol { r } - \alpha \boldsymbol { s }$
      \State $\kappa \leftarrow \langle \boldsymbol { r } , \boldsymbol { r } \rangle$
      \If{$ \kappa < \epsilon$} \Comment{alt. fixed amount of steps}
        \State \Return \label{alg:conj_grad:exit}
      \EndIf
      \State $\beta \gets \frac{\kappa}{\gamma}$
      \State $\boldsymbol { p } \leftarrow \boldsymbol { r } + \beta \boldsymbol { p }$
      \State $\gamma \gets \kappa$
      \Until{false} \Comment{exit at \ref{alg:conj_grad:exit}}
    \EndProcedure
  \end{algorithmic}
\end{algorithm}
Many minimization and finding zero crossing algorithms are available. One of such is Newton's Method, which allows for rapid quadratic convergence in a near local neighborhood.
\begin{equation}
  \boldsymbol{v}_i^{(i+1)} = \boldsymbol{v}^{(i)}_i + \left[\frac{\partial \boldsymbol{g}}{\partial \boldsymbol{v}}\left(\boldsymbol{v}^{(i)}_i\right)\right]^{-1}\boldsymbol{g}\left(\boldsymbol{v}^{(i)}_i\right)
\end{equation}
Computing the inverse is numerically irresponsible. Instead the following linear system is solved $\left(\Delta \boldsymbol{v} = \boldsymbol{v}_i^{(i+1)} - \boldsymbol{v}^{(i)}_i\right)$:
\begin{equation}\label{eq:linear_system}
  \left[\frac{\partial \boldsymbol{g}}{\partial \boldsymbol{v}}\left(\boldsymbol{v}^{(i)}_i\right)\right] \Delta \boldsymbol{v} =  \boldsymbol{g}\left(\boldsymbol{v}^{(i)}_i\right)
\end{equation}
Using the Newton's Method however requires a computation of the Hessian of $E(\boldsymbol{v}_i)$:
\begin{equation}
  \frac{\partial \boldsymbol{g}_i}{\partial \boldsymbol{v}_j} = \frac{m_i^n}{4} - \frac{\Delta t^2}{16}\frac{\partial \boldsymbol{f}_i}{\partial \boldsymbol{x}_j}\left(\boldsymbol{x}_i^n + \frac{\Delta t}{4} (\boldsymbol{v}_i + \boldsymbol{v}_i^{n})\right).
\end{equation}
Computing $\frac{\partial f_i}{\partial x_j}$ for every combination $ij$ would be quite memory-intensive. Instead immediately the matrix-vector product on an increment $\delta \boldsymbol{u}_j$ is solved:
\begin{equation}\label{eq:hessian-matrix-vector}
  \sum_j\frac{\partial \boldsymbol{g}_i}{\partial \boldsymbol{v}_j}\delta \boldsymbol{u}_j = \frac{m_i^n}{4}\delta \boldsymbol{u}_j - \frac{\Delta t^2}{16}\sum_j \frac{\partial \boldsymbol{f}_i}{\partial \boldsymbol{x}_j}\left(\boldsymbol{x}_i^n + \frac{\Delta t}{4} (\boldsymbol{v}_i + \boldsymbol{v}_i^{n})\right) \delta \boldsymbol{u}_j.
\end{equation}
The linear system can be solved with the conjugate gradient method (Algorithm \ref{alg:conj_grad}) since $\frac{\partial g}{\partial v}$ is symmetric, positive definite. This is due to being the Hessian of the convex function $E$. There is to important things notice:
\begin{enumerate}
  \item Conservation of momentum on incomplete convergence is only fulfilled if \ref{eq:linear_system} is premultiplied by the inverse diagonal mass matrix $M^{-1}$. More in \cite{MPM:APIC}. Thus the equation becomes:
    $$
      \left(\frac{1}{4} - \frac{\Delta t^2}{16}\frac{1}{m_i^n}\frac{\partial \boldsymbol{f}_i}{\partial \boldsymbol{x}_j}\left(\boldsymbol{x}_i^n + \frac{\Delta t}{4} (\boldsymbol{v}^{(i)}_i + \boldsymbol{v}_i^{n})\right)\right) \Delta v
      $$
    \begin{equation}
      = \frac{\boldsymbol{v}_i^{(i)}-\boldsymbol{v}_i^n}{4} -\frac{\Delta t}{4}\frac{1}{m_i^n}\boldsymbol{f}_i\left(\boldsymbol{x}_i^n + \frac{\Delta t}{4} (\boldsymbol{v}^{(i)}_i + \boldsymbol{v}_i^{n})\right).
    \end{equation}
  \item Due to \ref{eq:hessian-matrix-vector} the product of the Hessian with an increment ($\sum_j \frac{\partial \boldsymbol{f}_i}{\partial \boldsymbol{x}_j} \delta \boldsymbol{u}_j$) needs to be computed anew every step, since a pure matrix store is too costly.
\end{enumerate}
The Hessian increment can be computed with a two-stage process:
\begin{enumerate}
  \item Compute a particle quantity $\boldsymbol{A}_p$ with a grid to particle transfer:
    \begin{equation}
    \boldsymbol{A}_p = \frac { \partial ^ { 2 } \Psi } { \partial \boldsymbol { F } \partial \boldsymbol { F } } ( \hat { \boldsymbol { F } } _ { p } ( \hat { \boldsymbol { x } } )) : \left(\sum_j \delta \boldsymbol{u}_j (\nabla w_{jp}^n)^T \boldsymbol{F}^n_p\right).
    \end{equation}
  \item Compute the Hessian increment ($\delta \boldsymbol{f}_i$) with a particle to grid transfer:
\begin{equation}
  - \delta \boldsymbol{f}_i = - \sum_j \frac{\partial \boldsymbol{f}_i}{\partial \boldsymbol{x}_j} \delta \boldsymbol{u}_j = \sum_p V_p^0 \boldsymbol{A}_p(\boldsymbol{F}^n_p)^T \nabla w_{ip}^n.
\end{equation}
\end{enumerate}
\subsection{GPU memory}
\section{Implementation}
\subsection{Framework}
decorator pattern
\subsection{Optimization opportunities}
\cite{NVIDIA:BEST:PRACTICE}
\cite{AMD:GPU_OPEN}
\begin{itemize}
  \item Minimize CPU-GPU transfers
  \item Coalesced memory access
  \item Bank conflicts
\end{itemize}
\subsubsection{SoA vs. AoS}
\subsection{Parallel Reduction}
\cite{NVIDIA:PARALLEL_REDUCTION}
\subsection{Binning}
\cite{NVIDIA:BINNING}
\subsection{Scanning}
\cite{NVIDIA:SCAN}
\cite{NVIDIA:SCAN_MODERN}
\subsection{Affine particle-in-cell}
\cite{MPM:APIC}
\subsection{Iterative solvers for linear systems}
%GMRES, Conjugate Gradients
\subsection{Verifying Simulation}
\begin{itemize}
  \item Conservation equations
    \cite{MPM:APIC}
  \item Singular Value Decomposition
  \item Parallel Reduction
\end{itemize}
\section{Evaluation}
\cite{NVIDIA:PEAK_PERFORMANCE}
\cite{KHRONOS:TIMER_QUERY}
\section{Conclusion}
\subsection{Review}
\subsection{Future Work}
Particle Activation: \cite{MPM:GPU}

Sparse: \cite{OPENVDB} \cite{NVIDIA:GVDB_VOXELS}
\clearpage
\begin{appendices}
  \section{"Inertia Tensor" for Cubic Splines}\label{app:dp_proof}
  \begin{code}
\caption{$\boldsymbol{D}_p$ proof}
  \begin{minted}{python}
import numpy as np
from sympy import *

def round_expr(expr, num_digits):
  return expr.xreplace(
  {n : round(n, num_digits) for n in expr.atoms(Number)}
  )

# Limit a,b,c,x to interval [0,1] for simplyfing
a, b, c = symbols('a b c', nonnegative=true)
a = a/(1+a)
b = b/(1+b)
c = c/(1+c)

x = symbols('x', nonnegative=true)
x = x/(1+x)

# Define cubic interpolation function
def N1(x):
  return 0.5*pow(abs(x),3)-pow(x,2)+2/3
def N2(x):
  return -1/6*pow(abs(x),3)+pow(x,2)-2*abs(x)+4/3
def wip(i,x):
  if(i==1 or i==2):
    return N1(x)
  else:
    return N2(x)

# Define the parametrized position in the grid
def grid_points(x):
  return np.array([-x-1,-x,1-x,2-x])

alphas = grid_points(a)
betas = grid_points(b)
gammas = grid_points(c)

D_temp = np.array([[0,0,0],[0,0,0],[0,0,0]])

# Loop over all grid nodes in the vicinity
for i,ai in enumerate(alphas):
  for j,bj in enumerate(betas):
    for k,ck in enumerate(gammas):
      # xi_xp is the distance from parametrized
      # position to grid node [i,j,k]
      xi_xp = np.array([ai,bj,ck])
      # each outer product weighted by interpolation functions
      this_outer = wip(i,ai)*wip(j,bj)*wip(k,ck)*
		    np.outer(xi_xp,xi_xp)
      # summed up over all grid nodes
      D_temp = np.add(D_temp,this_outer)

D = np.array([[0.0,0.0,0.0],[0.0,0.0,0.0],[0.0,0.0,0.0]])

for i,D_row in enumerate(D_temp):
  for j,D_ij in enumerate(D_row):
    # simplify to cancel polynoms
    # round_expr because of numerical cancellation
    D[i][j] = round_expr(simplify(D_ij),14)
    print(D)
\end{minted}
\end{code}
  Prints out:
  $$
  \left[
    \begin{array}{ccc}
      0.33333333 &0.         &0.        \\
      0.         &0.33333333 &0.	\\
      0.         &0.         &0.33333333\\
  \end{array}\right]= \frac{\boldsymbol{D}_p}{h^2}
  $$
\end{appendices}
\clearpage
\listoffigures
\lstlistoflistings
\clearpage
\selectlanguage{english}
\printbibliography
\end{document}
